{
  "version": 3,
  "sources": ["../src/core/registry.ts", "../src/core/validation.ts", "../src/core/resolve.ts", "../src/core/undici.ts", "../src/core/transport.ts", "../src/providers/openai.ts", "../src/providers/anthropic.ts", "../src/providers/groq.ts", "../src/providers/openrouter.ts", "../src/providers/sambanova.ts", "../src/providers/gemini.ts", "../src/providers/cerebras.ts", "../src/providers/v1.ts", "../src/index.ts"],
  "sourcesContent": [
    "import type { Provider, ProviderId } from './types';\n\nexport class ProviderRegistry {\n  private providers = new Map<ProviderId, Provider>();\n\n  register(provider: Provider) {\n    this.providers.set(provider.id, provider);\n  }\n\n  get(id: ProviderId): Provider | undefined {\n    return this.providers.get(id);\n  }\n\n  has(id: ProviderId): boolean {\n    return this.providers.has(id);\n  }\n}\n",
    "import { object, string, number, boolean, array, optional, record, union } from 'dhi';\nimport type { ChatMessage, ChatRequest, ProviderId } from './types';\n\nconst ToolCallSchema = object({\n  id: string(),\n  type: string(),\n  function: object({\n    name: string(),\n    arguments: string(),\n  }),\n});\n\n// Multimodal content parts\nconst TextPartSchema = object({\n  type: string(), // 'text'\n  text: string(),\n});\nconst ImageUrlPartSchema = object({\n  type: string(), // 'image_url'\n  image_url: object({ url: string() }),\n});\nconst ContentSchema = union([string(), array(union([TextPartSchema, ImageUrlPartSchema]))]);\n\nconst ChatMessageSchema = object({\n  role: string(),\n  content: ContentSchema,\n  name: optional(string()),\n  tool_call_id: optional(string()),\n  tool_calls: optional(array(ToolCallSchema)),\n});\n\nexport const ChatRequestSchema = object({\n  provider: string(),\n  model: string(),\n  messages: array(ChatMessageSchema),\n  temperature: optional(number()),\n  max_tokens: optional(number()),\n  top_p: optional(number()),\n  stream: optional(boolean()),\n  json: optional(boolean()),\n  extraHeaders: optional(record(string())),\n});\n\nconst KNOWN_PROVIDERS_SET = new Set<ProviderId>([\n  'openai',\n  'anthropic',\n  'groq',\n  'gemini',\n  'openrouter',\n  'sambanova',\n  'cerebras',\n  'v1',\n]);\n\nexport function ensureKnownProvider(id: string): asserts id is ProviderId {\n  if (!KNOWN_PROVIDERS_SET.has(id as ProviderId)) {\n    throw new Error(`Unknown provider: ${id}`);\n  }\n}\n\nexport function validateChatRequest(req: unknown): ChatRequest {\n  const result = ChatRequestSchema.safeParse(req as any);\n  if (!result.success) {\n    const msg = result.error?.toString?.() ?? 'Invalid request';\n    throw new Error(msg);\n  }\n  ensureKnownProvider(result.data.provider);\n  const signal = (req as any)?.signal as AbortSignal | undefined;\n  // Preserve passthrough fields not in the strict schema (e.g., tools, tool_choice)\n  const { tools, tool_choice } = (req as any) || {};\n  return { ...(result.data as any), tools, tool_choice, signal } as ChatRequest;\n}\n",
    "import type { ProviderId } from './types';\n\n// Aliases for provider ids to improve DX (\"smart finder\")\nconst PROVIDER_ALIASES: Record<string, ProviderId> = {\n  // openai\n  openai: 'openai',\n  'open-ai': 'openai',\n  oai: 'openai',\n  // anthropic\n  anthropic: 'anthropic',\n  claude: 'anthropic',\n  // groq\n  groq: 'groq',\n  // gemini (Google)\n  gemini: 'gemini',\n  google: 'gemini',\n  'google-ai': 'gemini',\n  // openrouter\n  openrouter: 'openrouter',\n  'open-router': 'openrouter',\n  // sambanova\n  sambanova: 'sambanova',\n  samba: 'sambanova',\n  // cerebras\n  cerebras: 'cerebras',\n  'cerebras-ai': 'cerebras',\n  cs: 'cerebras',\n  // generic v1\n  v1: 'v1',\n  'openai-compatible': 'v1',\n  'oai-compat': 'v1',\n};\n\n// Model prefix heuristics to infer a provider when not specified\nconst MODEL_PREFIX_HINTS: Array<{ test: (m: string) => boolean; provider: ProviderId }> = [\n  { test: (m) => /^(gpt-|o[34](?:\\b|-|_)).*/i.test(m), provider: 'openai' },\n  { test: (m) => /^(claude-)/i.test(m), provider: 'anthropic' },\n  { test: (m) => /^(gemini-)/i.test(m), provider: 'gemini' },\n  { test: (m) => /^(llama|llama-?|meta-llama|mixtral|mistral)/i.test(m), provider: 'groq' },\n];\n\nfunction resolveProviderAlias(id: string | undefined): ProviderId | undefined {\n  if (!id) return undefined;\n  const key = id.trim().toLowerCase();\n  return PROVIDER_ALIASES[key];\n}\n\nfunction inferProviderFromModel(model: string | undefined): ProviderId | undefined {\n  if (!model) return undefined;\n  const m = model.trim();\n  for (const { test, provider } of MODEL_PREFIX_HINTS) {\n    if (test(m)) return provider;\n  }\n  return undefined;\n}\n\nexport type TargetLike = string | { target: string } | { provider?: string; model?: string };\n\nexport function parseTargetString(target: string): { provider?: ProviderId; model?: string } {\n  const raw = target.trim();\n  // Accept separators: '/', ':', or whitespace\n  const parts = raw.split(/[\\/:\\s]+/).filter(Boolean);\n  if (parts.length === 0) return {};\n\n  // If first token looks like a provider alias, use it; otherwise treat whole as model\n  const firstAsProvider = resolveProviderAlias(parts[0]);\n  if (firstAsProvider) {\n    const model = parts.slice(1).join('/');\n    return { provider: firstAsProvider, model: model || undefined };\n  }\n\n  // No clear provider; treat as model and try to infer provider from model name\n  const model = raw;\n  const inferred = inferProviderFromModel(model);\n  return { provider: inferred, model };\n}\n\nexport function normalizeProviderModel(input: TargetLike): { provider: ProviderId; model: string } {\n  // Cases:\n  // 1) string like 'openai/gpt-4o-mini' or 'gpt-4o-mini'\n  // 2) { target: 'openai gpt-4o-mini' }\n  // 3) { provider: 'openai', model: 'gpt-4o-mini' }\n  // 4) { provider: 'oai', model: 'gpt-4o-mini' } (alias)\n  // 5) { model: 'gpt-4o-mini' } with inference\n\n  let provider: ProviderId | undefined;\n  let model: string | undefined;\n\n  if (typeof input === 'string') {\n    const parsed = parseTargetString(input);\n    provider = parsed.provider;\n    model = parsed.model;\n  } else if ('target' in input && typeof input.target === 'string') {\n    const parsed = parseTargetString(input.target);\n    provider = parsed.provider;\n    model = parsed.model;\n  } else {\n    // provider/model fields potentially present\n    provider = resolveProviderAlias((input as any)?.provider);\n    model = (input as any)?.model;\n\n    // If provider was embedded like 'openai/gpt-4o-mini' in provider field\n    if ((!model || !provider) && typeof (input as any)?.provider === 'string' && (input as any).provider.includes('/')) {\n      const parsed = parseTargetString((input as any).provider);\n      provider = provider ?? parsed.provider;\n      model = model ?? parsed.model;\n    }\n\n    // If model field contains combined form 'openai/xxx'\n    if (typeof model === 'string' && model.includes('/')) {\n      const parsed = parseTargetString(model);\n      provider = provider ?? parsed.provider;\n      // When model contains provider/model, prefer the trailing actual model as model\n      if (parsed.model) model = parsed.model;\n    }\n\n    // If provider still missing, try inferring from model\n    if (!provider && typeof model === 'string') {\n      provider = inferProviderFromModel(model);\n    }\n  }\n\n  if (!provider || !model) {\n    const hint = `Accepts 'provider/model' (e.g. 'openai/gpt-4o-mini') or separate { provider, model }.`;\n    throw new Error(\n      `Could not resolve provider/model from input. ${hint}`\n    );\n  }\n\n  return { provider, model };\n}\n",
    "// Node-only undici dispatcher helper\n// Creates a per-origin Pool to maximize connection reuse in Node runtimes.\n\nlet pools: Map<string, any> | undefined;\n\nfunction isNode(): boolean {\n  try {\n    // eslint-disable-next-line no-undef\n    const p: any = typeof process !== 'undefined' ? process : undefined;\n    // Ensure we're on Node but NOT on Bun\n    return !!p?.versions?.node && !p?.versions?.bun;\n  } catch {\n    return false;\n  }\n}\n\nfunction originFrom(url: string): string | undefined {\n  try {\n    const u = new URL(url);\n    return `${u.protocol}//${u.host}`;\n  } catch {\n    return undefined;\n  }\n}\n\nexport async function getUndiciDispatcher(url: string): Promise<any | undefined> {\n  if (!isNode()) return undefined;\n  // Opt-out via env in Node (default is to try undici if available)\n  try {\n    // eslint-disable-next-line no-undef\n    const disable = (typeof process !== 'undefined' && (process as any).env?.HRI_USE_UNDICI) === '0';\n    if (disable) return undefined;\n  } catch {\n    // ignore env read errors\n  }\n\n  const origin = originFrom(url);\n  if (!origin) return undefined;\n  try {\n    const undici = await import('undici');\n    const { Pool } = undici as any;\n    if (!pools) pools = new Map<string, any>();\n    let pool = pools.get(origin);\n    if (!pool) {\n      pool = new Pool(origin, {\n        connections: 8,\n        pipelining: 1,\n        keepAliveTimeout: 10_000,\n        keepAliveMaxTimeout: 60_000,\n      });\n      pools.set(origin, pool);\n    }\n    return pool;\n  } catch {\n    // undici not available; silently skip\n    return undefined;\n  }\n}\n\n",
    "export type HeadersInit = Record<string, string>;\n\nexport interface RequestOptions {\n  method?: string;\n  headers?: HeadersInit;\n  body?: any;\n  signal?: AbortSignal;\n}\n\nexport function joinUrl(base: string, path: string): string {\n  if (path.startsWith('http')) return path;\n  return `${base.replace(/\\/$/, '')}/${path.replace(/^\\//, '')}`;\n}\n\nimport { getUndiciDispatcher } from './undici';\n\nexport async function http(url: string, opts: RequestOptions = {}): Promise<Response> {\n  const { method = 'POST', headers = {}, body, signal } = opts;\n  // Detect Node (not Bun) to decide whether to set keepalive explicitly\n  let isNodeNotBun = false;\n  try {\n    // eslint-disable-next-line no-undef\n    const p: any = typeof process !== 'undefined' ? process : undefined;\n    isNodeNotBun = !!p?.versions?.node && !p?.versions?.bun;\n  } catch {\n    isNodeNotBun = false;\n  }\n  const init: RequestInit = {\n    method,\n    headers,\n    body: typeof body === 'string' || body instanceof Uint8Array ? body : body ? JSON.stringify(body) : undefined,\n    signal,\n    // Hint the runtime to reuse connections across sequential requests\n    // to reduce TLS handshake/latency overhead in benchmarks.\n    // In Node, this can help with HTTP/1.1 servers; in Bun/Browser, omit to let runtime decide.\n    ...(isNodeNotBun ? { keepalive: true } : {}),\n  } as RequestInit;\n\n  // In Node, optionally use undici Pool dispatcher for stronger connection reuse.\n  const dispatcher = await getUndiciDispatcher(url);\n  if (dispatcher) {\n    (init as any).dispatcher = dispatcher;\n  }\n\n  return fetch(url, init);\n}\n\nexport async function* readLines(stream: ReadableStream<Uint8Array>): AsyncGenerator<string> {\n  const reader = stream.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n      buffer += decoder.decode(value, { stream: true });\n      let idx: number;\n      while ((idx = buffer.indexOf('\\n')) !== -1) {\n        const line = buffer.slice(0, idx);\n        buffer = buffer.slice(idx + 1);\n        yield line.replace(/\\r$/, '');\n      }\n    }\n    if (buffer.length > 0) {\n      yield buffer;\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\nexport async function* parseSSE(stream: ReadableStream<Uint8Array>): AsyncGenerator<{ event?: string; data?: string } | null> {\n  let dataLines: string[] = [];\n  let event: string | undefined;\n  for await (const line of readLines(stream)) {\n    if (line === '') {\n      const data = dataLines.length ? dataLines.join('\\n') : undefined;\n      yield data || event ? { event, data } : null;\n      dataLines = [];\n      event = undefined;\n      continue;\n    }\n    if (line.startsWith(':')) {\n      continue; // comment\n    }\n    const idx = line.indexOf(':');\n    const field = idx === -1 ? line : line.slice(0, idx);\n    const value = idx === -1 ? '' : line.slice(idx + 1).replace(/^\\s*/, '');\n    if (field === 'event') event = value;\n    else if (field === 'data') dataLines.push(value);\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.openai.com/v1';\n\nfunction toChatResponse(json: any, providerId: 'openai'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class OpenAIProvider implements Provider {\n  id = 'openai' as const;\n  name = 'OpenAI';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) {\n      body.response_format = { type: 'json_object' };\n    }\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`OpenAI error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) {\n      body.response_format = { type: 'json_object' };\n    }\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`OpenAI stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') {\n        return;\n      }\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch (e) {\n        // ignore parse errors for non-data lines\n      }\n    }\n  }\n\n  async listModels(apiKey?: string, baseUrl?: string): Promise<string[]> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/models');\n    const headers: Record<string, string> = {\n      'Authorization': `Bearer ${apiKey || ''}`,\n      'Accept': 'application/json',\n    };\n    const res = await http(url, { method: 'GET', headers });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`OpenAI models error ${res.status}: ${text}`);\n    }\n    const json: any = await res.json().catch(() => ({}));\n    if (Array.isArray(json?.data)) return json.data.map((m: any) => m?.id).filter(Boolean);\n    if (Array.isArray(json)) return json.filter((x) => typeof x === 'string');\n    return [];\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.anthropic.com';\nconst API_VERSION = '2023-06-01';\n\nfunction toAnthropicMessages(req: ChatRequest): { system?: string; messages: { role: 'user' | 'assistant'; content: string }[] } {\n  const systemParts: string[] = [];\n  const messages: { role: 'user' | 'assistant'; content: string }[] = [];\n\n  const toText = (c: ChatMessage['content']): string => {\n    if (typeof c === 'string') return c;\n    // Concatenate text parts; ignore image parts for this minimal mapping\n    return (c || [])\n      .map((p: any) => (p?.type === 'text' ? String(p.text ?? '') : ''))\n      .join('')\n      .trim();\n  };\n\n  for (const m of req.messages) {\n    if (m.role === 'system') {\n      systemParts.push(toText(m.content));\n    } else if (m.role === 'user' || m.role === 'assistant') {\n      messages.push({ role: m.role, content: toText(m.content) });\n    }\n    // ignore tool for now in stub\n  }\n  const system = systemParts.length ? systemParts.join('\\n') : undefined;\n  return { system, messages };\n}\n\nfunction toChatResponse(json: any, providerId: 'anthropic', model: string): ChatResponse {\n  const text = Array.isArray(json.content) ? json.content.map((b: any) => b.text || '').join('') : json.content?.[0]?.text || '';\n  const msg: ChatMessage = { role: 'assistant', content: text };\n  return {\n    id: json.id ?? 'unknown',\n    created: Math.floor(Date.now() / 1000),\n    model: model,\n    choices: [{ index: 0, message: msg, finish_reason: json.stop_reason ?? null }],\n    provider: providerId,\n    raw: json,\n  };\n}\n\nexport class AnthropicProvider implements Provider {\n  id = 'anthropic' as const;\n  name = 'Anthropic';\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const path = '/v1/messages';\n    const url = joinUrl(baseUrl || DEFAULT_BASE, path);\n    const { system, messages } = toAnthropicMessages(req);\n    const headers = {\n      'x-api-key': apiKey || '',\n      'content-type': 'application/json',\n      'anthropic-version': API_VERSION,\n      ...(req.extraHeaders || {}),\n    };\n    const body: any = {\n      model: req.model,\n      max_tokens: req.max_tokens ?? 1024,\n      temperature: req.temperature,\n      system,\n      messages,\n    };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Anthropic error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id, req.model);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const path = '/v1/messages';\n    const url = joinUrl(baseUrl || DEFAULT_BASE, path);\n    const { system, messages } = toAnthropicMessages(req);\n    const headers = {\n      'x-api-key': apiKey || '',\n      'content-type': 'application/json',\n      'accept': 'text/event-stream',\n      'anthropic-version': API_VERSION,\n      ...(req.extraHeaders || {}),\n    };\n    const body: any = {\n      model: req.model,\n      max_tokens: req.max_tokens ?? 1024,\n      temperature: req.temperature,\n      system,\n      messages,\n      stream: true,\n    };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Anthropic stream error ${res.status}: ${text}`);\n    }\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      try {\n        const json = JSON.parse(evt.data);\n        const type = json.type as string | undefined;\n        if (type === 'content_block_delta' && json.delta?.type === 'text_delta') {\n          const chunk: ChatStreamChunk = {\n            delta: { role: 'assistant', content: json.delta.text || '' },\n            raw: json,\n          };\n          yield chunk;\n        } else if (type === 'message_stop') {\n          return;\n        }\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.groq.com/openai/v1';\n\nfunction toChatResponse(json: any, providerId: 'groq'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class GroqProvider implements Provider {\n  id = 'groq' as const;\n  name = 'Groq (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Groq error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Groq stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n\n  async listModels(apiKey?: string, baseUrl?: string): Promise<string[]> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/models');\n    const headers: Record<string, string> = {\n      'Authorization': `Bearer ${apiKey || ''}`,\n      'Accept': 'application/json',\n    };\n    const res = await http(url, { method: 'GET', headers });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Groq models error ${res.status}: ${text}`);\n    }\n    const json: any = await res.json().catch(() => ({}));\n    if (Array.isArray(json?.data)) return json.data.map((m: any) => m?.id).filter(Boolean);\n    if (Array.isArray(json)) return json.filter((x) => typeof x === 'string');\n    return [];\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://openrouter.ai/api/v1';\n\nfunction toChatResponse(json: any, providerId: 'openrouter'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class OpenRouterProvider implements Provider {\n  id = 'openrouter' as const;\n  name = 'OpenRouter (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`OpenRouter error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`OpenRouter stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.sambanova.ai/v1';\n\nfunction toChatResponse(json: any, providerId: 'sambanova'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class SambaNovaProvider implements Provider {\n  id = 'sambanova' as const;\n  name = 'SambaNova (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`SambaNova error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`SambaNova stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\n// Google Generative Language OpenAI-compatible endpoint\nconst DEFAULT_BASE = 'https://generativelanguage.googleapis.com/v1beta/openai';\n\nfunction toChatResponse(json: any, providerId: 'gemini'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class GeminiProvider implements Provider {\n  id = 'gemini' as const;\n  name = 'Gemini (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Gemini error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Gemini stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.cerebras.ai/v1';\n\nfunction toChatResponse(json: any, providerId: 'cerebras'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class CerebrasProvider implements Provider {\n  id = 'cerebras' as const;\n  name = 'Cerebras (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Cerebras error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Cerebras stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n\n  async listModels(apiKey?: string, baseUrl?: string): Promise<string[]> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/models');\n    const headers: Record<string, string> = {\n      'Authorization': `Bearer ${apiKey || ''}`,\n      'Accept': 'application/json',\n    };\n    const res = await http(url, { method: 'GET', headers });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Cerebras models error ${res.status}: ${text}`);\n    }\n    const json: any = await res.json().catch(() => ({}));\n    if (Array.isArray(json?.data)) return json.data.map((m: any) => m?.id).filter(Boolean);\n    if (Array.isArray(json)) return json.filter((x) => typeof x === 'string');\n    return [];\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\n// Generic OpenAI v1-compatible provider. Base URL must be provided via config or proxy.\nconst DEFAULT_BASE: string | undefined = undefined;\n\nfunction toChatResponse(json: any, providerId: 'v1'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class V1Provider implements Provider {\n  id = 'v1' as const;\n  name = 'Generic V1 (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || (DEFAULT_BASE as string), '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`V1 error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || (DEFAULT_BASE as string), '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`V1 stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n\n  async listModels(apiKey?: string, baseUrl?: string): Promise<string[]> {\n    const url = joinUrl(baseUrl || (DEFAULT_BASE as string), '/models');\n    const headers: Record<string, string> = {\n      'Authorization': `Bearer ${apiKey || ''}`,\n      'Accept': 'application/json',\n    };\n    const res = await http(url, { method: 'GET', headers });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`V1 models error ${res.status}: ${text}`);\n    }\n    const json: any = await res.json().catch(() => ({}));\n    // Accept OpenAI-like { data: [{id: string}] } or plain array of ids\n    if (Array.isArray(json?.data)) {\n      return json.data.map((m: any) => m?.id).filter(Boolean);\n    }\n    if (Array.isArray(json)) return json.filter((x) => typeof x === 'string');\n    return [];\n  }\n}\n\n",
    "import { ProviderRegistry } from './core/registry';\nimport type {\n  ChatRequest,\n  ChatResponse,\n  ChatStreamChunk,\n  ProviderId,\n  Provider,\n  ClientConfig,\n  ChatMessage,\n  ToolDef,\n  ToolCall,\n} from './core/types';\nimport { validateChatRequest } from './core/validation';\nimport { normalizeProviderModel, type TargetLike } from './core/resolve';\nimport { OpenAIProvider } from './providers/openai';\nimport { AnthropicProvider } from './providers/anthropic';\nimport { GroqProvider } from './providers/groq';\nimport { OpenRouterProvider } from './providers/openrouter';\nimport { SambaNovaProvider } from './providers/sambanova';\nimport { GeminiProvider } from './providers/gemini';\nimport { CerebrasProvider } from './providers/cerebras';\nimport { V1Provider } from './providers/v1';\nimport { http, joinUrl } from './core/transport';\n\nexport * from './core/types';\nexport { validateChatRequest } from './core/validation';\nexport { ProviderRegistry } from './core/registry';\nexport { OpenAIProvider } from './providers/openai';\nexport { AnthropicProvider } from './providers/anthropic';\nexport { GroqProvider } from './providers/groq';\nexport { OpenRouterProvider } from './providers/openrouter';\nexport { SambaNovaProvider } from './providers/sambanova';\nexport { GeminiProvider } from './providers/gemini';\nexport { CerebrasProvider } from './providers/cerebras';\nexport { V1Provider } from './providers/v1';\n\nfunction env(name: string): string | undefined {\n  try {\n    // Bun/node\n    // eslint-disable-next-line no-undef\n    return (typeof process !== 'undefined' && process?.env?.[name]) || undefined;\n  } catch {\n    return undefined;\n  }\n}\n\nfunction keyFromEnv(provider: ProviderId): string | undefined {\n  const map: Record<ProviderId, string> = {\n    openai: 'OPENAI_API_KEY',\n    anthropic: 'ANTHROPIC_API_KEY',\n    groq: 'GROQ_API_KEY',\n    gemini: 'GEMINI_API_KEY',\n    openrouter: 'OPENROUTER_API_KEY',\n    sambanova: 'SAMBANOVA_API_KEY',\n    cerebras: 'CEREBRAS_API_KEY',\n    v1: 'V1_API_KEY',\n  };\n  return env(map[provider]);\n}\n\nfunction defaultBase(provider: ProviderId): string | undefined {\n  switch (provider) {\n    case 'openai':\n      return 'https://api.openai.com/v1';\n    case 'anthropic':\n      return 'https://api.anthropic.com';\n    default:\n      return undefined;\n  }\n}\n\nexport class HRI {\n  readonly registry: ProviderRegistry;\n  private config: ClientConfig;\n\n  constructor(config: ClientConfig = {}, registry?: ProviderRegistry) {\n    this.config = config;\n    this.registry = registry ?? new ProviderRegistry();\n  }\n\n  static createDefault(config: ClientConfig = {}): HRI {\n    const hri = new HRI(config);\n    hri.use(new OpenAIProvider());\n    hri.use(new AnthropicProvider());\n    hri.use(new GroqProvider());\n    hri.use(new OpenRouterProvider());\n    hri.use(new SambaNovaProvider());\n    hri.use(new GeminiProvider());\n    hri.use(new CerebrasProvider());\n    hri.use(new V1Provider());\n    return hri;\n  }\n\n  use(provider: Provider) {\n    this.registry.register(provider);\n    return this;\n  }\n\n  private apiKeyFor(provider: ProviderId): string | undefined {\n    return this.config.apiKeys?.[provider] ?? keyFromEnv(provider);\n  }\n\n  private baseUrlFor(provider: ProviderId): string | undefined {\n    if (this.config.baseUrls?.[provider]) return this.config.baseUrls[provider];\n    if (this.config.proxy) {\n      // Opinionated proxy mapping paths; user can override via baseUrls\n      switch (provider) {\n        case 'openai':\n          return `${this.config.proxy.replace(/\\/$/, '')}/openai/v1`;\n        case 'anthropic':\n          return `${this.config.proxy.replace(/\\/$/, '')}/anthropic`;\n        case 'v1':\n          return `${this.config.proxy.replace(/\\/$/, '')}/v1`;\n        default:\n          return this.config.proxy;\n      }\n    }\n    return defaultBase(provider);\n  }\n\n  // Overloads for easier DX\n  async chat(target: string, init: Omit<ChatRequest, 'provider' | 'model'>): Promise<ChatResponse>;\n  async chat(req: ChatRequest): Promise<ChatResponse>;\n  async chat(reqOrTarget: ChatRequest | string, init?: Omit<ChatRequest, 'provider' | 'model'>): Promise<ChatResponse> {\n    const normalized = this.normalizeInput(reqOrTarget as any, init as any);\n    const v = validateChatRequest(normalized);\n    const provider = this.registry.get(v.provider as ProviderId);\n    if (!provider) throw new Error(`Provider not registered: ${v.provider}`);\n    const key = this.apiKeyFor(provider.id);\n    const base = this.baseUrlFor(provider.id);\n    const res = await provider.chat({ ...v, stream: false }, key, base);\n    try {\n      this.config.onUsage?.(res.usage, { provider: provider.id, model: v.model });\n    } catch {\n      // user hook errors should not break flow\n    }\n    return res;\n  }\n\n  // Overloads for easier DX\n  streamChat(target: string, init: Omit<ChatRequest, 'provider' | 'model'> & { stream?: true }): AsyncIterable<ChatStreamChunk>;\n  streamChat(req: ChatRequest): AsyncIterable<ChatStreamChunk>;\n  streamChat(reqOrTarget: ChatRequest | string, init?: Omit<ChatRequest, 'provider' | 'model'> & { stream?: true }): AsyncIterable<ChatStreamChunk> {\n    const normalized = this.normalizeInput(reqOrTarget as any, { ...(init as any), stream: true });\n    const v = validateChatRequest({ ...normalized, stream: true });\n    const provider = this.registry.get(v.provider as ProviderId);\n    if (!provider || !provider.streamChat) {\n      throw new Error(`Provider does not support streaming: ${v.provider}`);\n    }\n    const key = this.apiKeyFor(provider.id);\n    const base = this.baseUrlFor(provider.id);\n    return provider.streamChat(v, key, base);\n  }\n\n  // Helper: aggregate streamed content to a single string\n  async streamToText(target: string, init: Omit<ChatRequest, 'provider' | 'model'> & { stream?: true }): Promise<string>;\n  async streamToText(req: ChatRequest): Promise<string>;\n  async streamToText(reqOrTarget: ChatRequest | string, init?: Omit<ChatRequest, 'provider' | 'model'> & { stream?: true }): Promise<string> {\n    const normalized = this.normalizeInput(reqOrTarget as any, { ...(init as any), stream: true });\n    let text = '';\n    for await (const c of this.streamChat({ ...normalized, stream: true })) {\n      const delta = c.delta?.content;\n      if (typeof delta === 'string') text += delta;\n    }\n    return text;\n  }\n\n  // Automatic Function Calling (OpenAI-compatible)\n  // Executes tool calls returned by the model until completion or maxCalls reached.\n  async chatWithTools(\n    req: ChatRequest & { tools?: ToolDef[]; tool_choice?: ChatRequest['tool_choice'] },\n    handlers: Record<string, (args: any) => any | Promise<any>>,\n    opts: { maxCalls?: number } = {}\n  ): Promise<ChatResponse> {\n    const maxCalls = opts.maxCalls ?? 10;\n    const messages: ChatMessage[] = [...req.messages];\n    let calls = 0;\n\n    // Allow forcing a first tool via tool_choice, but automatically switch to 'auto' after first round\n    let toolChoice = req.tool_choice;\n    while (calls <= maxCalls) {\n      const res = await this.chat({ ...req, messages, stream: false, tool_choice: toolChoice });\n      const choice = res.choices?.[0];\n      const msg = choice?.message as ChatMessage | undefined;\n      const toolCalls = (msg?.tool_calls as ToolCall[] | undefined) || [];\n\n      if (!toolCalls.length) {\n        return res;\n      }\n\n      // Append the assistant message containing the tool_calls\n      messages.push({ role: 'assistant', content: msg?.content || '', tool_calls: toolCalls });\n\n      // Execute tools and push tool results as messages\n      for (const tc of toolCalls) {\n        if (tc.type !== 'function') continue;\n        const name = tc.function?.name;\n        const handler = handlers[name];\n        let args: any = {};\n        try {\n          args = tc.function?.arguments ? JSON.parse(tc.function.arguments) : {};\n        } catch {\n          args = {};\n        }\n        let out: any;\n        try {\n          if (!handler) throw new Error(`No handler for tool: ${name}`);\n          out = await handler(args);\n        } catch (e: any) {\n          out = { error: String(e?.message || e) };\n        }\n        const content = typeof out === 'string' ? out : JSON.stringify(out);\n        messages.push({ role: 'tool', content, tool_call_id: tc.id });\n      }\n\n      calls += 1;\n      if (toolChoice === 'required' || (toolChoice && typeof toolChoice === 'object')) {\n        toolChoice = 'none';\n      } else {\n        toolChoice = 'auto';\n      }\n      // Next loop will send updated messages; keep tools in request and continue.\n      // Optionally, user may set tool_choice:'none' in req to force a final answer.\n    }\n\n    throw new Error(`Exceeded max tool calls (${maxCalls}) during chatWithTools()`);\n  }\n\n  // Streaming AFC (OpenAI-compatible)\n  // Yields chunks as they arrive; when a tool_calls finish is reached, executes tools and continues streaming.\n  async *streamWithTools(\n    req: ChatRequest & { tools?: ToolDef[]; tool_choice?: ChatRequest['tool_choice'] },\n    handlers: Record<string, (args: any) => any | Promise<any>>,\n    opts: { maxCalls?: number } = {}\n  ): AsyncIterable<ChatStreamChunk> {\n    const maxCalls = opts.maxCalls ?? 10;\n    const baseReq = { ...req, stream: true } as ChatRequest;\n    const messages: ChatMessage[] = [...req.messages];\n    let calls = 0;\n\n    // Allow a first forced tool_choice, then revert to 'auto'\n    let toolChoice = req.tool_choice;\n    while (calls <= maxCalls) {\n      const stream = this.streamChat({ ...baseReq, messages, tool_choice: toolChoice });\n      // Accumulate tool_calls deltas by id\n      const toolAccum = new Map<string, { name: string | undefined; args: string }>();\n      for await (const chunk of stream) {\n        // Aggregate tool call delta if present\n        const deltas = chunk.delta?.tool_calls || [];\n        for (const t of deltas) {\n          if (!t) continue;\n          const id = t.id || '0';\n          const acc = toolAccum.get(id) ?? { name: t.function?.name, args: '' };\n          if (t.function?.name) acc.name = t.function.name;\n          if (t.function?.arguments) acc.args += t.function.arguments;\n          toolAccum.set(id, acc);\n        }\n        yield chunk;\n      }\n\n      // If no tool calls were emitted during this streamed turn, end streaming\n      if (toolAccum.size === 0) return;\n\n      // Append assistant message with tool_calls (filter invalid entries without a function name)\n      const toolCalls = Array.from(toolAccum.entries())\n        .filter(([, v]) => v.name && v.name.length > 0)\n        .map(([id, v]) => ({\n          id,\n          type: 'function' as const,\n          function: { name: v.name as string, arguments: v.args || '{}' },\n        }));\n\n      // If nothing valid accumulated, end the stream gracefully\n      if (toolCalls.length === 0) return;\n      messages.push({ role: 'assistant', content: '', tool_calls: toolCalls });\n\n      // Execute and append tool results\n      for (const tc of toolCalls) {\n        const handler = handlers[tc.function.name];\n        let args: any = {};\n        try {\n          args = tc.function.arguments ? JSON.parse(tc.function.arguments) : {};\n        } catch {\n          args = {};\n        }\n        let out: any;\n        try {\n          if (!handler) throw new Error(`No handler for tool: ${tc.function.name}`);\n          out = await handler(args);\n        } catch (e: any) {\n          out = { error: String(e?.message || e) };\n        }\n        const content = typeof out === 'string' ? out : JSON.stringify(out);\n        messages.push({ role: 'tool', content, tool_call_id: tc.id });\n      }\n\n      calls += 1;\n      // After a tool round: if the initial choice was 'required' or a specific function,\n      // force a final answer to avoid infinite tool loops; otherwise fall back to 'auto'.\n      if (toolChoice === 'required' || (toolChoice && typeof toolChoice === 'object')) {\n        toolChoice = 'none';\n      } else {\n        toolChoice = 'auto';\n      }\n      // Loop to continue streaming the follow-up model response\n    }\n\n    throw new Error(`Exceeded max tool calls (${maxCalls}) during streamWithTools()`);\n  }\n\n  // Verify if a model exists for a provider by querying /models when supported\n  async verifyModel(target: string | ChatRequest): Promise<{ exists: boolean; provider: ProviderId; model: string; models?: string[]; status?: number; error?: string }>{\n    const normalized = this.normalizeInput(target as any);\n    const { provider: pid, model } = normalized;\n    const provider = this.registry.get(pid);\n    if (!provider) throw new Error(`Provider not registered: ${pid}`);\n    const key = this.apiKeyFor(pid);\n    const base = this.baseUrlFor(pid);\n    // Prefer provider-implemented listModels\n    try {\n      if (provider.listModels) {\n        const models = await provider.listModels(key, base);\n        const exists = !!models?.includes(model);\n        return { exists, provider: pid, model, models };\n      }\n    } catch (e: any) {\n      return { exists: false, provider: pid, model, error: String(e?.message || e) };\n    }\n\n    // Fallback: attempt generic OpenAI v1 /models\n    if (!base) return { exists: false, provider: pid, model, error: 'Base URL is not configured for provider; cannot query /models.' };\n    try {\n      const url = joinUrl(base, '/models');\n      const headers: Record<string, string> = { 'Authorization': `Bearer ${key || ''}`, 'Accept': 'application/json' };\n      const res = await http(url, { method: 'GET', headers });\n      if (!res.ok) {\n        const text = await res.text();\n        const status = res.status;\n        let hint = 'Unknown error querying /models.';\n        if (status === 401) hint = 'Unauthorized: API key missing or invalid.';\n        else if (status === 403) hint = 'Forbidden: key lacks permission for /models.';\n        else if (status === 404) hint = 'Not found: base URL may be wrong (no /models).';\n        else if (status >= 500) hint = 'Provider server error (5xx).';\n        return { exists: false, provider: pid, model, status, error: `${hint} ${text}` };\n      }\n      const json: any = await res.json().catch(() => ({}));\n      const models: string[] = Array.isArray(json?.data) ? json.data.map((m: any) => m?.id).filter(Boolean) : Array.isArray(json) ? json.filter((x) => typeof x === 'string') : [];\n      const exists = !!models?.includes(model);\n      return { exists, provider: pid, model, models };\n    } catch (e: any) {\n      const msg = String(e?.message || e);\n      const corsHint = msg.includes('fetch failed') ? 'Network/CORS/proxy error while calling /models.' : '';\n      return { exists: false, provider: pid, model, error: [corsHint, msg].filter(Boolean).join(' ') };\n    }\n  }\n\n  // Internal: normalize various DX-friendly inputs to a strict ChatRequest\n  private normalizeInput(reqOrTarget: ChatRequest | string | TargetLike, init?: PartialChatInit): ChatRequest {\n    if (typeof reqOrTarget === 'string') {\n      const { provider, model } = normalizeProviderModel(reqOrTarget);\n      const base: any = { ...(init || {}) };\n      const messages = base.messages || [];\n      return { ...base, provider, model, messages } as ChatRequest;\n    }\n    const base: any = { ...(reqOrTarget as any), ...(init || {}) };\n    const { provider, model } = normalizeProviderModel(base as any);\n    const { target: _omit, ...rest } = base;\n    return { ...rest, provider, model } as ChatRequest;\n  }\n}\n// Helper type for overloads\nexport interface PartialChatInit extends Partial<Omit<ChatRequest, 'provider' | 'model'>> {\n  provider?: string;\n  model?: string;\n  target?: string;\n}\n"
  ],
  "mappings": "omBAEO,MAAM,CAAiB,CACpB,UAAY,IAAI,IAExB,QAAQ,CAAC,EAAoB,CAC3B,KAAK,UAAU,IAAI,EAAS,GAAI,CAAQ,EAG1C,GAAG,CAAC,EAAsC,CACxC,OAAO,KAAK,UAAU,IAAI,CAAE,EAG9B,GAAG,CAAC,EAAyB,CAC3B,OAAO,KAAK,UAAU,IAAI,CAAE,EAEhC,CChBA,iBAAS,YAAQ,YAAQ,aAAQ,WAAS,cAAO,YAAU,YAAQ,YAGnE,IAAM,GAAiB,EAAO,CAC5B,GAAI,EAAO,EACX,KAAM,EAAO,EACb,SAAU,EAAO,CACf,KAAM,EAAO,EACb,UAAW,EAAO,CACpB,CAAC,CACH,CAAC,EAGK,GAAiB,EAAO,CAC5B,KAAM,EAAO,EACb,KAAM,EAAO,CACf,CAAC,EACK,GAAqB,EAAO,CAChC,KAAM,EAAO,EACb,UAAW,EAAO,CAAE,IAAK,EAAO,CAAE,CAAC,CACrC,CAAC,EACK,GAAgB,EAAM,CAAC,EAAO,EAAG,EAAM,EAAM,CAAC,GAAgB,EAAkB,CAAC,CAAC,CAAC,CAAC,EAEpF,GAAoB,EAAO,CAC/B,KAAM,EAAO,EACb,QAAS,GACT,KAAM,EAAS,EAAO,CAAC,EACvB,aAAc,EAAS,EAAO,CAAC,EAC/B,WAAY,EAAS,EAAM,EAAc,CAAC,CAC5C,CAAC,EAEY,GAAoB,EAAO,CACtC,SAAU,EAAO,EACjB,MAAO,EAAO,EACd,SAAU,EAAM,EAAiB,EACjC,YAAa,EAAS,EAAO,CAAC,EAC9B,WAAY,EAAS,EAAO,CAAC,EAC7B,MAAO,EAAS,EAAO,CAAC,EACxB,OAAQ,EAAS,EAAQ,CAAC,EAC1B,KAAM,EAAS,EAAQ,CAAC,EACxB,aAAc,EAAS,GAAO,EAAO,CAAC,CAAC,CACzC,CAAC,EAEK,GAAsB,IAAI,IAAgB,CAC9C,SACA,YACA,OACA,SACA,aACA,YACA,WACA,IACF,CAAC,EAEM,SAAS,EAAmB,CAAC,EAAsC,CACxE,IAAK,GAAoB,IAAI,CAAgB,EAC3C,MAAM,IAAI,MAAM,qBAAqB,GAAI,EAItC,SAAS,CAAmB,CAAC,EAA2B,CAC7D,IAAM,EAAS,GAAkB,UAAU,CAAU,EACrD,IAAK,EAAO,QAAS,CACnB,IAAM,EAAM,EAAO,OAAO,WAAW,GAAK,kBAC1C,MAAM,IAAI,MAAM,CAAG,EAErB,GAAoB,EAAO,KAAK,QAAQ,EACxC,IAAM,EAAU,GAAa,QAErB,QAAO,eAAiB,GAAe,CAAC,EAChD,MAAO,IAAM,EAAO,KAAc,QAAO,cAAa,QAAO,ECnE/D,IAAM,GAA+C,CAEnD,OAAQ,SACR,UAAW,SACX,IAAK,SAEL,UAAW,YACX,OAAQ,YAER,KAAM,OAEN,OAAQ,SACR,OAAQ,SACR,YAAa,SAEb,WAAY,aACZ,cAAe,aAEf,UAAW,YACX,MAAO,YAEP,SAAU,WACV,cAAe,WACf,GAAI,WAEJ,GAAI,KACJ,oBAAqB,KACrB,aAAc,IAChB,EAGM,GAAoF,CACxF,CAAE,KAAM,CAAC,IAAM,6BAA6B,KAAK,CAAC,EAAG,SAAU,QAAS,EACxE,CAAE,KAAM,CAAC,IAAM,cAAc,KAAK,CAAC,EAAG,SAAU,WAAY,EAC5D,CAAE,KAAM,CAAC,IAAM,cAAc,KAAK,CAAC,EAAG,SAAU,QAAS,EACzD,CAAE,KAAM,CAAC,IAAM,+CAA+C,KAAK,CAAC,EAAG,SAAU,MAAO,CAC1F,EAEA,SAAS,CAAoB,CAAC,EAAgD,CAC5E,IAAK,EAAI,OACT,IAAM,EAAM,EAAG,KAAK,EAAE,YAAY,EAClC,OAAO,GAAiB,GAG1B,SAAS,CAAsB,CAAC,EAAmD,CACjF,IAAK,EAAO,OACZ,IAAM,EAAI,EAAM,KAAK,EACrB,QAAa,OAAM,cAAc,GAC/B,GAAI,EAAK,CAAC,EAAG,OAAO,EAEtB,OAKK,SAAS,CAAiB,CAAC,EAA2D,CAC3F,IAAM,EAAM,EAAO,KAAK,EAElB,EAAQ,EAAI,MAAM,UAAU,EAAE,OAAO,OAAO,EAClD,GAAI,EAAM,SAAW,EAAG,MAAO,CAAC,EAGhC,IAAM,EAAkB,EAAqB,EAAM,EAAE,EACrD,GAAI,EAAiB,CACnB,IAAM,EAAQ,EAAM,MAAM,CAAC,EAAE,KAAK,GAAG,EACrC,MAAO,CAAE,SAAU,EAAiB,MAAO,GAAS,MAAU,EAIhE,IAAM,EAAQ,EAEd,MAAO,CAAE,SADQ,EAAuB,CAAK,EAChB,OAAM,EAG9B,SAAS,CAAsB,CAAC,EAA4D,CAQjG,IAAI,EACA,EAEJ,GAAI,OAAO,IAAU,SAAU,CAC7B,IAAM,EAAS,EAAkB,CAAK,EACtC,EAAW,EAAO,SAClB,EAAQ,EAAO,MACV,QAAI,WAAY,GAAS,OAAO,EAAM,SAAW,SAAU,CAChE,IAAM,EAAS,EAAkB,EAAM,MAAM,EAC7C,EAAW,EAAO,SAClB,EAAQ,EAAO,MACV,KAML,GAJA,EAAW,EAAsB,GAAe,QAAQ,EACxD,EAAS,GAAe,QAGlB,IAAU,IAAa,OAAQ,GAAe,WAAa,UAAa,EAAc,SAAS,SAAS,GAAG,EAAG,CAClH,IAAM,EAAS,EAAmB,EAAc,QAAQ,EACxD,EAAW,GAAY,EAAO,SAC9B,EAAQ,GAAS,EAAO,MAI1B,GAAI,OAAO,IAAU,UAAY,EAAM,SAAS,GAAG,EAAG,CACpD,IAAM,EAAS,EAAkB,CAAK,EAGtC,GAFA,EAAW,GAAY,EAAO,SAE1B,EAAO,MAAO,EAAQ,EAAO,MAInC,IAAK,GAAY,OAAO,IAAU,SAChC,EAAW,EAAuB,CAAK,EAI3C,IAAK,IAAa,EAEhB,MAAM,IAAI,MACR,oIACF,EAGF,MAAO,CAAE,WAAU,OAAM,EC9H3B,IAAI,EAEJ,SAAS,EAAM,EAAY,CACzB,GAAI,CAEF,IAAM,EAAS,OAAO,UAAY,YAAc,QAAU,OAE1D,QAAS,GAAG,UAAU,OAAS,GAAG,UAAU,IAC5C,KAAM,CACN,MAAO,IAIX,SAAS,EAAU,CAAC,EAAiC,CACnD,GAAI,CACF,IAAM,EAAI,IAAI,IAAI,CAAG,EACrB,MAAO,GAAG,EAAE,aAAa,EAAE,OAC3B,KAAM,CACN,QAIJ,eAAsB,CAAmB,CAAC,EAAuC,CAC/E,IAAK,GAAO,EAAG,OAEf,GAAI,CAGF,IADiB,OAAO,UAAY,aAAgB,QAAgB,KAAK,kBAAoB,IAChF,OACb,KAAM,EAIR,IAAM,EAAS,GAAW,CAAG,EAC7B,IAAK,EAAQ,OACb,GAAI,CACF,IAAM,EAAS,KAAa,mBACpB,QAAS,EACjB,IAAK,EAAO,EAAQ,IAAI,IACxB,IAAI,EAAO,EAAM,IAAI,CAAM,EAC3B,IAAK,EACH,EAAO,IAAI,EAAK,EAAQ,CACtB,YAAa,EACb,WAAY,EACZ,iBAAkB,IAClB,oBAAqB,KACvB,CAAC,EACD,EAAM,IAAI,EAAQ,CAAI,EAExB,OAAO,EACP,KAAM,CAEN,QC9CG,SAAS,CAAO,CAAC,EAAc,EAAsB,CAC1D,GAAI,EAAK,WAAW,MAAM,EAAG,OAAO,EACpC,MAAO,GAAG,EAAK,QAAQ,MAAO,EAAE,KAAK,EAAK,QAAQ,MAAO,EAAE,IAK7D,eAAsB,CAAI,CAAC,EAAa,EAAuB,CAAC,EAAsB,CACpF,IAAQ,SAAS,OAAQ,UAAU,CAAC,EAAG,OAAM,UAAW,EAEpD,EAAe,GACnB,GAAI,CAEF,IAAM,EAAS,OAAO,UAAY,YAAc,QAAU,OAC1D,IAAiB,GAAG,UAAU,OAAS,GAAG,UAAU,IACpD,KAAM,CACN,EAAe,GAEjB,IAAM,EAAoB,CACxB,SACA,UACA,KAAM,OAAO,IAAS,UAAY,aAAgB,WAAa,EAAO,EAAO,KAAK,UAAU,CAAI,EAAI,OACpG,YAII,EAAe,CAAE,UAAW,EAAK,EAAI,CAAC,CAC5C,EAGM,EAAa,MAAM,EAAoB,CAAG,EAChD,GAAI,EACD,EAAa,WAAa,EAG7B,OAAO,MAAM,EAAK,CAAI,EAGxB,eAAuB,EAAS,CAAC,EAA4D,CAC3F,IAAM,EAAS,EAAO,UAAU,EAC1B,EAAU,IAAI,YAChB,EAAS,GACb,GAAI,CACF,MAAO,GAAM,CACX,IAAQ,OAAM,SAAU,MAAM,EAAO,KAAK,EAC1C,GAAI,EAAM,MACV,GAAU,EAAQ,OAAO,EAAO,CAAE,OAAQ,EAAK,CAAC,EAChD,IAAI,EACJ,OAAQ,EAAM,EAAO,QAAQ;AAAA,CAAI,KAAO,GAAI,CAC1C,IAAM,EAAO,EAAO,MAAM,EAAG,CAAG,EAChC,EAAS,EAAO,MAAM,EAAM,CAAC,EAC7B,MAAM,EAAK,QAAQ,MAAO,EAAE,GAGhC,GAAI,EAAO,OAAS,EAClB,MAAM,SAER,CACA,EAAO,YAAY,GAIvB,eAAuB,CAAQ,CAAC,EAA8F,CAC5H,IAAI,EAAsB,CAAC,EACvB,EACJ,cAAiB,KAAQ,GAAU,CAAM,EAAG,CAC1C,GAAI,IAAS,GAAI,CACf,IAAM,EAAO,EAAU,OAAS,EAAU,KAAK;AAAA,CAAI,EAAI,OACvD,MAAM,GAAQ,EAAQ,CAAE,QAAO,MAAK,EAAI,KACxC,EAAY,CAAC,EACb,EAAQ,OACR,SAEF,GAAI,EAAK,WAAW,GAAG,EACrB,SAEF,IAAM,EAAM,EAAK,QAAQ,GAAG,EACtB,EAAQ,IAAQ,GAAK,EAAO,EAAK,MAAM,EAAG,CAAG,EAC7C,EAAQ,IAAQ,GAAK,GAAK,EAAK,MAAM,EAAM,CAAC,EAAE,QAAQ,OAAQ,EAAE,EACtE,GAAI,IAAU,QAAS,EAAQ,EAC1B,QAAI,IAAU,OAAQ,EAAU,KAAK,CAAK,GCtFnD,IAAM,EAAe,4BAErB,SAAS,EAAc,CAAC,EAAW,EAAoC,CACrE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAmC,CAC9C,GAAK,SACL,KAAO,SACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KACN,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE/C,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,gBAAgB,EAAI,WAAW,GAAM,EAEvD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KACN,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAG/C,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,uBAAuB,EAAI,WAAW,GAAM,EAG9D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SACf,OAEF,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,MAAO,EAAG,SAMV,WAAU,CAAC,EAAiB,EAAqC,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,SAAS,EAChD,EAAkC,CACtC,cAAiB,UAAU,GAAU,KACrC,OAAU,kBACZ,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,MAAO,SAAQ,CAAC,EACtD,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,uBAAuB,EAAI,WAAW,GAAM,EAE9D,IAAM,EAAY,MAAM,EAAI,KAAK,EAAE,MAAM,KAAO,CAAC,EAAE,EACnD,GAAI,MAAM,QAAQ,GAAM,IAAI,EAAG,OAAO,EAAK,KAAK,IAAI,CAAC,IAAW,GAAG,EAAE,EAAE,OAAO,OAAO,EACrF,GAAI,MAAM,QAAQ,CAAI,EAAG,OAAO,EAAK,OAAO,CAAC,IAAM,OAAO,IAAM,QAAQ,EACxE,MAAO,CAAC,EAEZ,CCvJA,IAAM,EAAe,4BACf,EAAc,aAEpB,SAAS,CAAmB,CAAC,EAAoG,CAC/H,IAAM,EAAwB,CAAC,EACzB,EAA8D,CAAC,EAE/D,EAAS,CAAC,IAAsC,CACpD,GAAI,OAAO,IAAM,SAAU,OAAO,EAElC,OAAQ,GAAK,CAAC,GACX,IAAI,CAAC,IAAY,GAAG,OAAS,OAAS,OAAO,EAAE,MAAQ,EAAE,EAAI,EAAG,EAChE,KAAK,EAAE,EACP,KAAK,GAGV,QAAW,KAAK,EAAI,SAClB,GAAI,EAAE,OAAS,SACb,EAAY,KAAK,EAAO,EAAE,OAAO,CAAC,EAC7B,QAAI,EAAE,OAAS,QAAU,EAAE,OAAS,YACzC,EAAS,KAAK,CAAE,KAAM,EAAE,KAAM,QAAS,EAAO,EAAE,OAAO,CAAE,CAAC,EAK9D,MAAO,CAAE,OADM,EAAY,OAAS,EAAY,KAAK;AAAA,CAAI,EAAI,OAC5C,UAAS,EAG5B,SAAS,EAAc,CAAC,EAAW,EAAyB,EAA6B,CAEvF,IAAM,EAAmB,CAAE,KAAM,YAAa,QADjC,MAAM,QAAQ,EAAK,OAAO,EAAI,EAAK,QAAQ,IAAI,CAAC,IAAW,EAAE,MAAQ,EAAE,EAAE,KAAK,EAAE,EAAI,EAAK,UAAU,IAAI,MAAQ,EAChE,EAC5D,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrC,MAAO,EACP,QAAS,CAAC,CAAE,MAAO,EAAG,QAAS,EAAK,cAAe,EAAK,aAAe,IAAK,CAAC,EAC7E,SAAU,EACV,IAAK,CACP,EAGK,MAAM,CAAsC,CACjD,GAAK,YACL,KAAO,iBAED,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CAErF,IAAM,EAAM,EAAQ,GAAW,EADlB,cACoC,GACzC,SAAQ,YAAa,EAAoB,CAAG,EAC9C,EAAU,CACd,YAAa,GAAU,GACvB,eAAgB,mBAChB,oBAAqB,KACjB,EAAI,cAAgB,CAAC,CAC3B,EACM,EAAY,CAChB,MAAO,EAAI,MACX,WAAY,EAAI,YAAc,KAC9B,YAAa,EAAI,YACjB,SACA,UACF,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAE1D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,GAAI,EAAI,KAAK,QAGzC,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CAErE,IAAM,EAAM,EAAQ,GAAW,EADlB,cACoC,GACzC,SAAQ,YAAa,EAAoB,CAAG,EAC9C,EAAU,CACd,YAAa,GAAU,GACvB,eAAgB,mBAChB,OAAU,oBACV,oBAAqB,KACjB,EAAI,cAAgB,CAAC,CAC3B,EACM,EAAY,CAChB,MAAO,EAAI,MACX,WAAY,EAAI,YAAc,KAC9B,YAAa,EAAI,YACjB,SACA,WACA,OAAQ,EACV,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,0BAA0B,EAAI,WAAW,GAAM,EAEjE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAO,EAAK,KAClB,GAAI,IAAS,uBAAyB,EAAK,OAAO,OAAS,aAKzD,KAJ+B,CAC7B,MAAO,CAAE,KAAM,YAAa,QAAS,EAAK,MAAM,MAAQ,EAAG,EAC3D,IAAK,CACP,EAEK,QAAI,IAAS,eAClB,OAEF,KAAM,IAKd,CClHA,IAAM,EAAe,iCAErB,SAAS,EAAc,CAAC,EAAW,EAAkC,CACnE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAiC,CAC5C,GAAK,OACL,KAAO,2BACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,cAAc,EAAI,WAAW,GAAM,EAErD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,qBAAqB,EAAI,WAAW,GAAM,EAG5D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,SAMN,WAAU,CAAC,EAAiB,EAAqC,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,SAAS,EAChD,EAAkC,CACtC,cAAiB,UAAU,GAAU,KACrC,OAAU,kBACZ,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,MAAO,SAAQ,CAAC,EACtD,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,qBAAqB,EAAI,WAAW,GAAM,EAE5D,IAAM,EAAY,MAAM,EAAI,KAAK,EAAE,MAAM,KAAO,CAAC,EAAE,EACnD,GAAI,MAAM,QAAQ,GAAM,IAAI,EAAG,OAAO,EAAK,KAAK,IAAI,CAAC,IAAW,GAAG,EAAE,EAAE,OAAO,OAAO,EACrF,GAAI,MAAM,QAAQ,CAAI,EAAG,OAAO,EAAK,OAAO,CAAC,IAAM,OAAO,IAAM,QAAQ,EACxE,MAAO,CAAC,EAEZ,CCjJA,IAAM,GAAe,+BAErB,SAAS,EAAc,CAAC,EAAW,EAAwC,CACzE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,EAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAuC,CAClD,GAAK,aACL,KAAO,iCACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,oBAAoB,EAAI,WAAW,GAAM,EAE3D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,2BAA2B,EAAI,WAAW,GAAM,EAGlE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CChIA,IAAM,GAAe,8BAErB,SAAS,EAAc,CAAC,EAAW,EAAuC,CACxE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,EAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAsC,CACjD,GAAK,YACL,KAAO,gCACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAE1D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,0BAA0B,EAAI,WAAW,GAAM,EAGjE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CC/HA,IAAM,GAAe,0DAErB,SAAS,EAAc,CAAC,EAAW,EAAoC,CACrE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,EAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAmC,CAC9C,GAAK,SACL,KAAO,6BACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,gBAAgB,EAAI,WAAW,GAAM,EAEvD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,GAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,uBAAuB,EAAI,WAAW,GAAM,EAG9D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CCjIA,IAAM,EAAe,6BAErB,SAAS,EAAc,CAAC,EAAW,EAAsC,CACvE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,EAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAqC,CAChD,GAAK,WACL,KAAO,+BACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,kBAAkB,EAAI,WAAW,GAAM,EAEzD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,yBAAyB,EAAI,WAAW,GAAM,EAGhE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,SAMN,WAAU,CAAC,EAAiB,EAAqC,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,SAAS,EAChD,EAAkC,CACtC,cAAiB,UAAU,GAAU,KACrC,OAAU,kBACZ,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,MAAO,SAAQ,CAAC,EACtD,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,yBAAyB,EAAI,WAAW,GAAM,EAEhE,IAAM,EAAY,MAAM,EAAI,KAAK,EAAE,MAAM,KAAO,CAAC,EAAE,EACnD,GAAI,MAAM,QAAQ,GAAM,IAAI,EAAG,OAAO,EAAK,KAAK,IAAI,CAAC,IAAW,GAAG,EAAE,EAAE,OAAO,OAAO,EACrF,GAAI,MAAM,QAAQ,CAAI,EAAG,OAAO,EAAK,OAAO,CAAC,IAAM,OAAO,IAAM,QAAQ,EACxE,MAAO,CAAC,EAEZ,CChJA,IAAM,EAAmC,OAEzC,SAAS,EAAc,CAAC,EAAW,EAAgC,CACjE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,EAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAA+B,CAC1C,GAAK,KACL,KAAO,iCACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAY,EAAyB,mBAAmB,EACtE,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,YAAY,EAAI,WAAW,GAAM,EAEnD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAY,EAAyB,mBAAmB,EACtE,EAAU,GACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAG1D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,SAMN,WAAU,CAAC,EAAiB,EAAqC,CACrE,IAAM,EAAM,EAAQ,GAAY,EAAyB,SAAS,EAC5D,EAAkC,CACtC,cAAiB,UAAU,GAAU,KACrC,OAAU,kBACZ,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,MAAO,SAAQ,CAAC,EACtD,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAE1D,IAAM,EAAY,MAAM,EAAI,KAAK,EAAE,MAAM,KAAO,CAAC,EAAE,EAEnD,GAAI,MAAM,QAAQ,GAAM,IAAI,EAC1B,OAAO,EAAK,KAAK,IAAI,CAAC,IAAW,GAAG,EAAE,EAAE,OAAO,OAAO,EAExD,GAAI,MAAM,QAAQ,CAAI,EAAG,OAAO,EAAK,OAAO,CAAC,IAAM,OAAO,IAAM,QAAQ,EACxE,MAAO,CAAC,EAEZ,CCpHA,SAAS,EAAG,CAAC,EAAkC,CAC7C,GAAI,CAGF,OAAQ,OAAO,UAAY,aAAe,SAAS,MAAM,IAAU,OACnE,KAAM,CACN,QAIJ,SAAS,EAAU,CAAC,EAA0C,CAW5D,OAAO,GAViC,CACtC,OAAQ,iBACR,UAAW,oBACX,KAAM,eACN,OAAQ,iBACR,WAAY,qBACZ,UAAW,oBACX,SAAU,mBACV,GAAI,YACN,EACe,EAAS,EAG1B,SAAS,EAAW,CAAC,EAA0C,CAC7D,OAAQ,OACD,SACH,MAAO,gCACJ,YACH,MAAO,oCAEP,QAIC,MAAM,EAAI,CACN,SACD,OAER,WAAW,CAAC,EAAuB,CAAC,EAAG,EAA6B,CAClE,KAAK,OAAS,EACd,KAAK,SAAW,GAAY,IAAI,QAG3B,cAAa,CAAC,EAAuB,CAAC,EAAQ,CACnD,IAAM,EAAM,IAAI,GAAI,CAAM,EAS1B,OARA,EAAI,IAAI,IAAI,CAAgB,EAC5B,EAAI,IAAI,IAAI,CAAmB,EAC/B,EAAI,IAAI,IAAI,CAAc,EAC1B,EAAI,IAAI,IAAI,CAAoB,EAChC,EAAI,IAAI,IAAI,CAAmB,EAC/B,EAAI,IAAI,IAAI,CAAgB,EAC5B,EAAI,IAAI,IAAI,CAAkB,EAC9B,EAAI,IAAI,IAAI,CAAY,EACjB,EAGT,GAAG,CAAC,EAAoB,CAEtB,OADA,KAAK,SAAS,SAAS,CAAQ,EACxB,KAGD,SAAS,CAAC,EAA0C,CAC1D,OAAO,KAAK,OAAO,UAAU,IAAa,GAAW,CAAQ,EAGvD,UAAU,CAAC,EAA0C,CAC3D,GAAI,KAAK,OAAO,WAAW,GAAW,OAAO,KAAK,OAAO,SAAS,GAClE,GAAI,KAAK,OAAO,MAEd,OAAQ,OACD,SACH,MAAO,GAAG,KAAK,OAAO,MAAM,QAAQ,MAAO,EAAE,kBAC1C,YACH,MAAO,GAAG,KAAK,OAAO,MAAM,QAAQ,MAAO,EAAE,kBAC1C,KACH,MAAO,GAAG,KAAK,OAAO,MAAM,QAAQ,MAAO,EAAE,eAE7C,OAAO,KAAK,OAAO,MAGzB,OAAO,GAAY,CAAQ,OAMvB,KAAI,CAAC,EAAmC,EAAuE,CACnH,IAAM,EAAa,KAAK,eAAe,EAAoB,CAAW,EAChE,EAAI,EAAoB,CAAU,EAClC,EAAW,KAAK,SAAS,IAAI,EAAE,QAAsB,EAC3D,IAAK,EAAU,MAAM,IAAI,MAAM,4BAA4B,EAAE,UAAU,EACvE,IAAM,EAAM,KAAK,UAAU,EAAS,EAAE,EAChC,EAAO,KAAK,WAAW,EAAS,EAAE,EAClC,EAAM,MAAM,EAAS,KAAK,IAAK,EAAG,OAAQ,EAAM,EAAG,EAAK,CAAI,EAClE,GAAI,CACF,KAAK,OAAO,UAAU,EAAI,MAAO,CAAE,SAAU,EAAS,GAAI,MAAO,EAAE,KAAM,CAAC,EAC1E,KAAM,EAGR,OAAO,EAMT,UAAU,CAAC,EAAmC,EAAoG,CAChJ,IAAM,EAAa,KAAK,eAAe,EAAoB,IAAM,EAAc,OAAQ,EAAK,CAAC,EACvF,EAAI,EAAoB,IAAK,EAAY,OAAQ,EAAK,CAAC,EACvD,EAAW,KAAK,SAAS,IAAI,EAAE,QAAsB,EAC3D,IAAK,IAAa,EAAS,WACzB,MAAM,IAAI,MAAM,wCAAwC,EAAE,UAAU,EAEtE,IAAM,EAAM,KAAK,UAAU,EAAS,EAAE,EAChC,EAAO,KAAK,WAAW,EAAS,EAAE,EACxC,OAAO,EAAS,WAAW,EAAG,EAAK,CAAI,OAMnC,aAAY,CAAC,EAAmC,EAAqF,CACzI,IAAM,EAAa,KAAK,eAAe,EAAoB,IAAM,EAAc,OAAQ,EAAK,CAAC,EACzF,EAAO,GACX,cAAiB,KAAK,KAAK,WAAW,IAAK,EAAY,OAAQ,EAAK,CAAC,EAAG,CACtE,IAAM,EAAQ,EAAE,OAAO,QACvB,GAAI,OAAO,IAAU,SAAU,GAAQ,EAEzC,OAAO,OAKH,cAAa,CACjB,EACA,EACA,EAA8B,CAAC,EACR,CACvB,IAAM,EAAW,EAAK,UAAY,GAC5B,EAA0B,CAAC,GAAG,EAAI,QAAQ,EAC5C,EAAQ,EAGR,EAAa,EAAI,YACrB,MAAO,GAAS,EAAU,CACxB,IAAM,EAAM,MAAM,KAAK,KAAK,IAAK,EAAK,WAAU,OAAQ,GAAO,YAAa,CAAW,CAAC,EAElF,EADS,EAAI,UAAU,IACT,QACd,EAAa,GAAK,YAAyC,CAAC,EAElE,IAAK,EAAU,OACb,OAAO,EAIT,EAAS,KAAK,CAAE,KAAM,YAAa,QAAS,GAAK,SAAW,GAAI,WAAY,CAAU,CAAC,EAGvF,QAAW,KAAM,EAAW,CAC1B,GAAI,EAAG,OAAS,WAAY,SAC5B,IAAM,EAAO,EAAG,UAAU,KACpB,EAAU,EAAS,GACrB,EAAY,CAAC,EACjB,GAAI,CACF,EAAO,EAAG,UAAU,UAAY,KAAK,MAAM,EAAG,SAAS,SAAS,EAAI,CAAC,EACrE,KAAM,CACN,EAAO,CAAC,EAEV,IAAI,EACJ,GAAI,CACF,IAAK,EAAS,MAAM,IAAI,MAAM,wBAAwB,GAAM,EAC5D,EAAM,MAAM,EAAQ,CAAI,EACxB,MAAO,EAAQ,CACf,EAAM,CAAE,MAAO,OAAO,GAAG,SAAW,CAAC,CAAE,EAEzC,IAAM,EAAU,OAAO,IAAQ,SAAW,EAAM,KAAK,UAAU,CAAG,EAClE,EAAS,KAAK,CAAE,KAAM,OAAQ,UAAS,aAAc,EAAG,EAAG,CAAC,EAI9D,GADA,GAAS,EACL,IAAe,YAAe,GAAc,OAAO,IAAe,SACpE,EAAa,OAEb,OAAa,OAMjB,MAAM,IAAI,MAAM,4BAA4B,2BAAkC,QAKzE,eAAe,CACpB,EACA,EACA,EAA8B,CAAC,EACC,CAChC,IAAM,EAAW,EAAK,UAAY,GAC5B,EAAU,IAAK,EAAK,OAAQ,EAAK,EACjC,EAA0B,CAAC,GAAG,EAAI,QAAQ,EAC5C,EAAQ,EAGR,EAAa,EAAI,YACrB,MAAO,GAAS,EAAU,CACxB,IAAM,EAAS,KAAK,WAAW,IAAK,EAAS,WAAU,YAAa,CAAW,CAAC,EAE1E,EAAY,IAAI,IACtB,cAAiB,KAAS,EAAQ,CAEhC,IAAM,EAAS,EAAM,OAAO,YAAc,CAAC,EAC3C,QAAW,KAAK,EAAQ,CACtB,IAAK,EAAG,SACR,IAAM,EAAK,EAAE,IAAM,IACb,EAAM,EAAU,IAAI,CAAE,GAAK,CAAE,KAAM,EAAE,UAAU,KAAM,KAAM,EAAG,EACpE,GAAI,EAAE,UAAU,KAAM,EAAI,KAAO,EAAE,SAAS,KAC5C,GAAI,EAAE,UAAU,UAAW,EAAI,MAAQ,EAAE,SAAS,UAClD,EAAU,IAAI,EAAI,CAAG,EAEvB,MAAM,EAIR,GAAI,EAAU,OAAS,EAAG,OAG1B,IAAM,EAAY,MAAM,KAAK,EAAU,QAAQ,CAAC,EAC7C,OAAO,GAAI,KAAO,EAAE,MAAQ,EAAE,KAAK,OAAS,CAAC,EAC7C,IAAI,EAAE,EAAI,MAAQ,CACjB,KACA,KAAM,WACN,SAAU,CAAE,KAAM,EAAE,KAAgB,UAAW,EAAE,MAAQ,IAAK,CAChE,EAAE,EAGJ,GAAI,EAAU,SAAW,EAAG,OAC5B,EAAS,KAAK,CAAE,KAAM,YAAa,QAAS,GAAI,WAAY,CAAU,CAAC,EAGvE,QAAW,KAAM,EAAW,CAC1B,IAAM,EAAU,EAAS,EAAG,SAAS,MACjC,EAAY,CAAC,EACjB,GAAI,CACF,EAAO,EAAG,SAAS,UAAY,KAAK,MAAM,EAAG,SAAS,SAAS,EAAI,CAAC,EACpE,KAAM,CACN,EAAO,CAAC,EAEV,IAAI,EACJ,GAAI,CACF,IAAK,EAAS,MAAM,IAAI,MAAM,wBAAwB,EAAG,SAAS,MAAM,EACxE,EAAM,MAAM,EAAQ,CAAI,EACxB,MAAO,EAAQ,CACf,EAAM,CAAE,MAAO,OAAO,GAAG,SAAW,CAAC,CAAE,EAEzC,IAAM,EAAU,OAAO,IAAQ,SAAW,EAAM,KAAK,UAAU,CAAG,EAClE,EAAS,KAAK,CAAE,KAAM,OAAQ,UAAS,aAAc,EAAG,EAAG,CAAC,EAM9D,GAHA,GAAS,EAGL,IAAe,YAAe,GAAc,OAAO,IAAe,SACpE,EAAa,OAEb,OAAa,OAKjB,MAAM,IAAI,MAAM,4BAA4B,6BAAoC,OAI5E,YAAW,CAAC,EAAoJ,CACpK,IAAM,EAAa,KAAK,eAAe,CAAa,GAC5C,SAAU,EAAK,SAAU,EAC3B,EAAW,KAAK,SAAS,IAAI,CAAG,EACtC,IAAK,EAAU,MAAM,IAAI,MAAM,4BAA4B,GAAK,EAChE,IAAM,EAAM,KAAK,UAAU,CAAG,EACxB,EAAO,KAAK,WAAW,CAAG,EAEhC,GAAI,CACF,GAAI,EAAS,WAAY,CACvB,IAAM,EAAS,MAAM,EAAS,WAAW,EAAK,CAAI,EAElD,MAAO,CAAE,SADQ,GAAQ,SAAS,CAAK,EACtB,SAAU,EAAK,QAAO,QAAO,GAEhD,MAAO,EAAQ,CACf,MAAO,CAAE,OAAQ,GAAO,SAAU,EAAK,QAAO,MAAO,OAAO,GAAG,SAAW,CAAC,CAAE,EAI/E,IAAK,EAAM,MAAO,CAAE,OAAQ,GAAO,SAAU,EAAK,QAAO,MAAO,gEAAiE,EACjI,GAAI,CACF,IAAM,EAAM,EAAQ,EAAM,SAAS,EAC7B,EAAkC,CAAE,cAAiB,UAAU,GAAO,KAAM,OAAU,kBAAmB,EACzG,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,MAAO,SAAQ,CAAC,EACtD,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EACtB,EAAS,EAAI,OACf,EAAO,kCACX,GAAI,IAAW,IAAK,EAAO,4CACtB,QAAI,IAAW,IAAK,EAAO,+CAC3B,QAAI,IAAW,IAAK,EAAO,iDAC3B,QAAI,GAAU,IAAK,EAAO,+BAC/B,MAAO,CAAE,OAAQ,GAAO,SAAU,EAAK,QAAO,SAAQ,MAAO,GAAG,KAAQ,GAAO,EAEjF,IAAM,EAAY,MAAM,EAAI,KAAK,EAAE,MAAM,KAAO,CAAC,EAAE,EAC7C,EAAmB,MAAM,QAAQ,GAAM,IAAI,EAAI,EAAK,KAAK,IAAI,CAAC,IAAW,GAAG,EAAE,EAAE,OAAO,OAAO,EAAI,MAAM,QAAQ,CAAI,EAAI,EAAK,OAAO,CAAC,IAAM,OAAO,IAAM,QAAQ,EAAI,CAAC,EAE3K,MAAO,CAAE,SADQ,GAAQ,SAAS,CAAK,EACtB,SAAU,EAAK,QAAO,QAAO,EAC9C,MAAO,EAAQ,CACf,IAAM,EAAM,OAAO,GAAG,SAAW,CAAC,EAC5B,EAAW,EAAI,SAAS,cAAc,EAAI,kDAAoD,GACpG,MAAO,CAAE,OAAQ,GAAO,SAAU,EAAK,QAAO,MAAO,CAAC,EAAU,CAAG,EAAE,OAAO,OAAO,EAAE,KAAK,GAAG,CAAE,GAK3F,cAAc,CAAC,EAAgD,EAAqC,CAC1G,GAAI,OAAO,IAAgB,SAAU,CACnC,IAAQ,WAAU,SAAU,EAAuB,CAAW,EACxD,EAAY,IAAM,GAAQ,CAAC,CAAG,EAC9B,EAAW,EAAK,UAAY,CAAC,EACnC,MAAO,IAAK,EAAM,WAAU,QAAO,UAAS,EAE9C,IAAM,EAAY,IAAM,KAAyB,GAAQ,CAAC,CAAG,GACrD,WAAU,SAAU,EAAuB,CAAW,GACtD,OAAQ,KAAU,GAAS,EACnC,MAAO,IAAK,EAAM,WAAU,OAAM,EAEtC",
  "debugId": "EA310D8E257254E964756E2164756E21",
  "names": []
}