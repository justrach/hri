{
  "version": 3,
  "sources": ["../src/core/registry.ts", "../src/core/validation.ts", "../src/core/undici.ts", "../src/core/transport.ts", "../src/providers/openai.ts", "../src/providers/anthropic.ts", "../src/providers/groq.ts", "../src/providers/openrouter.ts", "../src/providers/sambanova.ts", "../src/providers/gemini.ts", "../src/index.ts"],
  "sourcesContent": [
    "import type { Provider, ProviderId } from './types';\n\nexport class ProviderRegistry {\n  private providers = new Map<ProviderId, Provider>();\n\n  register(provider: Provider) {\n    this.providers.set(provider.id, provider);\n  }\n\n  get(id: ProviderId): Provider | undefined {\n    return this.providers.get(id);\n  }\n\n  has(id: ProviderId): boolean {\n    return this.providers.has(id);\n  }\n}\n",
    "import { object, string, number, boolean, array, optional, record } from 'dhi';\nimport type { ChatMessage, ChatRequest, ProviderId } from './types';\n\nconst ToolCallSchema = object({\n  id: string(),\n  type: string(),\n  function: object({\n    name: string(),\n    arguments: string(),\n  }),\n});\n\nconst ChatMessageSchema = object({\n  role: string(),\n  content: string(),\n  name: optional(string()),\n  tool_call_id: optional(string()),\n  tool_calls: optional(array(ToolCallSchema)),\n});\n\nexport const ChatRequestSchema = object({\n  provider: string(),\n  model: string(),\n  messages: array(ChatMessageSchema),\n  temperature: optional(number()),\n  max_tokens: optional(number()),\n  top_p: optional(number()),\n  stream: optional(boolean()),\n  json: optional(boolean()),\n  extraHeaders: optional(record(string())),\n});\n\nexport function ensureKnownProvider(id: string): asserts id is ProviderId {\n  const known: ProviderId[] = ['openai', 'anthropic', 'groq', 'gemini', 'openrouter', 'sambanova'];\n  if (!known.includes(id as ProviderId)) {\n    throw new Error(`Unknown provider: ${id}`);\n  }\n}\n\nexport function validateChatRequest(req: unknown): ChatRequest {\n  const result = ChatRequestSchema.safeParse(req as any);\n  if (!result.success) {\n    const msg = result.error?.toString?.() ?? 'Invalid request';\n    throw new Error(msg);\n  }\n  ensureKnownProvider(result.data.provider);\n  const signal = (req as any)?.signal as AbortSignal | undefined;\n  // Preserve passthrough fields not in the strict schema (e.g., tools, tool_choice)\n  const { tools, tool_choice } = (req as any) || {};\n  return { ...(result.data as any), tools, tool_choice, signal } as ChatRequest;\n}\n",
    "// Node-only optional undici dispatcher helper\n// Creates a per-origin Pool to maximize connection reuse in Node runtimes.\n\nlet pools: Map<string, any> | undefined;\n\nfunction isNode(): boolean {\n  try {\n    // eslint-disable-next-line no-undef\n    return typeof process !== 'undefined' && !!(process as any).versions?.node;\n  } catch {\n    return false;\n  }\n}\n\nfunction originFrom(url: string): string | undefined {\n  try {\n    const u = new URL(url);\n    return `${u.protocol}//${u.host}`;\n  } catch {\n    return undefined;\n  }\n}\n\nexport async function getUndiciDispatcher(url: string): Promise<any | undefined> {\n  if (!isNode()) return undefined;\n  // Opt-in via env to avoid surprises in Bun/browsers\n  try {\n    // eslint-disable-next-line no-undef\n    const use = (typeof process !== 'undefined' && (process as any).env?.HRI_USE_UNDICI) === '1';\n    if (!use) return undefined;\n  } catch {\n    return undefined;\n  }\n\n  const origin = originFrom(url);\n  if (!origin) return undefined;\n  try {\n    const undici = await import('undici');\n    const { Pool } = undici as any;\n    if (!pools) pools = new Map<string, any>();\n    let pool = pools.get(origin);\n    if (!pool) {\n      pool = new Pool(origin, {\n        connections: 8,\n        pipelining: 1,\n        keepAliveTimeout: 10_000,\n        keepAliveMaxTimeout: 60_000,\n      });\n      pools.set(origin, pool);\n    }\n    return pool;\n  } catch {\n    // undici not available; silently skip\n    return undefined;\n  }\n}\n\n",
    "export type HeadersInit = Record<string, string>;\n\nexport interface RequestOptions {\n  method?: string;\n  headers?: HeadersInit;\n  body?: any;\n  signal?: AbortSignal;\n}\n\nexport function joinUrl(base: string, path: string): string {\n  if (path.startsWith('http')) return path;\n  return `${base.replace(/\\/$/, '')}/${path.replace(/^\\//, '')}`;\n}\n\nimport { getUndiciDispatcher } from './undici';\n\nexport async function http(url: string, opts: RequestOptions = {}): Promise<Response> {\n  const { method = 'POST', headers = {}, body, signal } = opts;\n  const init: RequestInit = {\n    method,\n    headers,\n    body: typeof body === 'string' || body instanceof Uint8Array ? body : body ? JSON.stringify(body) : undefined,\n    signal,\n    // Hint the runtime to reuse connections across sequential requests\n    // to reduce TLS handshake/latency overhead in benchmarks.\n    keepalive: true,\n  } as RequestInit;\n\n  // In Node, optionally use undici Pool dispatcher for stronger connection reuse.\n  const dispatcher = await getUndiciDispatcher(url);\n  if (dispatcher) {\n    (init as any).dispatcher = dispatcher;\n  }\n\n  return fetch(url, init);\n}\n\nexport async function* readLines(stream: ReadableStream<Uint8Array>): AsyncGenerator<string> {\n  const reader = stream.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n      buffer += decoder.decode(value, { stream: true });\n      let idx: number;\n      while ((idx = buffer.indexOf('\\n')) !== -1) {\n        const line = buffer.slice(0, idx);\n        buffer = buffer.slice(idx + 1);\n        yield line.replace(/\\r$/, '');\n      }\n    }\n    if (buffer.length > 0) {\n      yield buffer;\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\nexport async function* parseSSE(stream: ReadableStream<Uint8Array>): AsyncGenerator<{ event?: string; data?: string } | null> {\n  let dataLines: string[] = [];\n  let event: string | undefined;\n  for await (const line of readLines(stream)) {\n    if (line === '') {\n      const data = dataLines.length ? dataLines.join('\\n') : undefined;\n      yield data || event ? { event, data } : null;\n      dataLines = [];\n      event = undefined;\n      continue;\n    }\n    if (line.startsWith(':')) {\n      continue; // comment\n    }\n    const idx = line.indexOf(':');\n    const field = idx === -1 ? line : line.slice(0, idx);\n    const value = idx === -1 ? '' : line.slice(idx + 1).replace(/^\\s*/, '');\n    if (field === 'event') event = value;\n    else if (field === 'data') dataLines.push(value);\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.openai.com/v1';\n\nfunction toChatResponse(json: any, providerId: 'openai'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class OpenAIProvider implements Provider {\n  id = 'openai' as const;\n  name = 'OpenAI';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) {\n      body.response_format = { type: 'json_object' };\n    }\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`OpenAI error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) {\n      body.response_format = { type: 'json_object' };\n    }\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`OpenAI stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') {\n        return;\n      }\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch (e) {\n        // ignore parse errors for non-data lines\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.anthropic.com';\nconst API_VERSION = '2023-06-01';\n\nfunction toAnthropicMessages(req: ChatRequest): { system?: string; messages: { role: 'user' | 'assistant'; content: string }[] } {\n  const systemParts: string[] = [];\n  const messages: { role: 'user' | 'assistant'; content: string }[] = [];\n  for (const m of req.messages) {\n    if (m.role === 'system') {\n      systemParts.push(m.content);\n    } else if (m.role === 'user' || m.role === 'assistant') {\n      messages.push({ role: m.role, content: m.content });\n    }\n    // ignore tool for now in stub\n  }\n  const system = systemParts.length ? systemParts.join('\\n') : undefined;\n  return { system, messages };\n}\n\nfunction toChatResponse(json: any, providerId: 'anthropic', model: string): ChatResponse {\n  const text = Array.isArray(json.content) ? json.content.map((b: any) => b.text || '').join('') : json.content?.[0]?.text || '';\n  const msg: ChatMessage = { role: 'assistant', content: text };\n  return {\n    id: json.id ?? 'unknown',\n    created: Math.floor(Date.now() / 1000),\n    model: model,\n    choices: [{ index: 0, message: msg, finish_reason: json.stop_reason ?? null }],\n    provider: providerId,\n    raw: json,\n  };\n}\n\nexport class AnthropicProvider implements Provider {\n  id = 'anthropic' as const;\n  name = 'Anthropic';\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const path = '/v1/messages';\n    const url = joinUrl(baseUrl || DEFAULT_BASE, path);\n    const { system, messages } = toAnthropicMessages(req);\n    const headers = {\n      'x-api-key': apiKey || '',\n      'content-type': 'application/json',\n      'anthropic-version': API_VERSION,\n      ...(req.extraHeaders || {}),\n    };\n    const body: any = {\n      model: req.model,\n      max_tokens: req.max_tokens ?? 1024,\n      temperature: req.temperature,\n      system,\n      messages,\n    };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Anthropic error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id, req.model);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const path = '/v1/messages';\n    const url = joinUrl(baseUrl || DEFAULT_BASE, path);\n    const { system, messages } = toAnthropicMessages(req);\n    const headers = {\n      'x-api-key': apiKey || '',\n      'content-type': 'application/json',\n      'accept': 'text/event-stream',\n      'anthropic-version': API_VERSION,\n      ...(req.extraHeaders || {}),\n    };\n    const body: any = {\n      model: req.model,\n      max_tokens: req.max_tokens ?? 1024,\n      temperature: req.temperature,\n      system,\n      messages,\n      stream: true,\n    };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Anthropic stream error ${res.status}: ${text}`);\n    }\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      try {\n        const json = JSON.parse(evt.data);\n        const type = json.type as string | undefined;\n        if (type === 'content_block_delta' && json.delta?.type === 'text_delta') {\n          const chunk: ChatStreamChunk = {\n            delta: { role: 'assistant', content: json.delta.text || '' },\n            raw: json,\n          };\n          yield chunk;\n        } else if (type === 'message_stop') {\n          return;\n        }\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.groq.com/openai/v1';\n\nfunction toChatResponse(json: any, providerId: 'groq'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class GroqProvider implements Provider {\n  id = 'groq' as const;\n  name = 'Groq (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Groq error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Groq stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://openrouter.ai/api/v1';\n\nfunction toChatResponse(json: any, providerId: 'openrouter'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class OpenRouterProvider implements Provider {\n  id = 'openrouter' as const;\n  name = 'OpenRouter (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`OpenRouter error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`OpenRouter stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\nconst DEFAULT_BASE = 'https://api.sambanova.ai/v1';\n\nfunction toChatResponse(json: any, providerId: 'sambanova'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class SambaNovaProvider implements Provider {\n  id = 'sambanova' as const;\n  name = 'SambaNova (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`SambaNova error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`SambaNova stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { http, joinUrl, parseSSE } from '../core/transport';\nimport type { Provider, ChatRequest, ChatResponse, ChatStreamChunk, ChatMessage } from '../core/types';\n\n// Google Generative Language OpenAI-compatible endpoint\nconst DEFAULT_BASE = 'https://generativelanguage.googleapis.com/v1beta/openai';\n\nfunction toChatResponse(json: any, providerId: 'gemini'): ChatResponse {\n  const choices = (json.choices ?? []).map((c: any, i: number) => ({\n    index: c.index ?? i,\n    message: (c.message ?? { role: 'assistant', content: '' }) as ChatMessage,\n    finish_reason: c.finish_reason ?? null,\n  }));\n  return {\n    id: json.id ?? 'unknown',\n    created: json.created ?? Math.floor(Date.now() / 1000),\n    model: json.model ?? 'unknown',\n    choices,\n    usage: json.usage,\n    provider: providerId,\n    raw: json,\n  };\n}\n\nfunction mergeHeaders(a?: Record<string, string>, b?: Record<string, string>): Record<string, string> {\n  return { ...(a || {}), ...(b || {}) };\n}\n\nexport class GeminiProvider implements Provider {\n  id = 'gemini' as const;\n  name = 'Gemini (OpenAI-compatible)';\n  private isGpt5(model: string): boolean {\n    try { return /(^|\\/)gpt-5/i.test(model); } catch { return false; }\n  }\n\n  async chat(req: ChatRequest, apiKey?: string, baseUrl?: string): Promise<ChatResponse> {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: false,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok) {\n      const text = await res.text();\n      throw new Error(`Gemini error ${res.status}: ${text}`);\n    }\n    const json = await res.json();\n    return toChatResponse(json, this.id);\n  }\n\n  async *streamChat(req: ChatRequest, apiKey?: string, baseUrl?: string) {\n    const url = joinUrl(baseUrl || DEFAULT_BASE, '/chat/completions');\n    const headers = mergeHeaders(\n      {\n        'Authorization': `Bearer ${apiKey || ''}`,\n        'Content-Type': 'application/json',\n        'Accept': 'text/event-stream',\n      },\n      req.extraHeaders\n    );\n    const body: any = {\n      model: req.model,\n      messages: req.messages,\n      temperature: req.temperature,\n      top_p: req.top_p,\n      stream: true,\n    };\n    if (req.max_tokens != null) {\n      if (this.isGpt5(req.model)) (body as any).max_completion_tokens = req.max_tokens;\n      else (body as any).max_tokens = req.max_tokens;\n    }\n    if (req.tools) body.tools = req.tools;\n    if (req.tool_choice) body.tool_choice = req.tool_choice;\n    if (req.json) body.response_format = { type: 'json_object' };\n\n    const res = await http(url, { method: 'POST', headers, body, signal: req.signal });\n    if (!res.ok || !res.body) {\n      const text = await res.text();\n      throw new Error(`Gemini stream error ${res.status}: ${text}`);\n    }\n\n    for await (const evt of parseSSE(res.body)) {\n      if (!evt || !evt.data) continue;\n      if (evt.data === '[DONE]') return;\n      try {\n        const json = JSON.parse(evt.data);\n        const choice = json.choices?.[0];\n        const delta = choice?.delta || {};\n        const chunk: ChatStreamChunk = {\n          id: json.id,\n          created: json.created,\n          model: json.model,\n          delta: {\n            role: delta.role,\n            content: delta.content,\n            tool_calls: Array.isArray(delta.tool_calls)\n              ? delta.tool_calls.map((t: any) => ({\n                  id: t.id ?? String(t.index ?? 0),\n                  type: 'function',\n                  function: {\n                    name: t.function?.name,\n                    arguments: t.function?.arguments ?? '',\n                  },\n                }))\n              : undefined,\n          },\n          finish_reason: choice?.finish_reason ?? null,\n          raw: json,\n        };\n        yield chunk;\n      } catch {\n        // ignore\n      }\n    }\n  }\n}\n",
    "import { ProviderRegistry } from './core/registry';\nimport type {\n  ChatRequest,\n  ChatResponse,\n  ChatStreamChunk,\n  ProviderId,\n  Provider,\n  ClientConfig,\n  ChatMessage,\n  ToolDef,\n  ToolCall,\n} from './core/types';\nimport { validateChatRequest } from './core/validation';\nimport { OpenAIProvider } from './providers/openai';\nimport { AnthropicProvider } from './providers/anthropic';\nimport { GroqProvider } from './providers/groq';\nimport { OpenRouterProvider } from './providers/openrouter';\nimport { SambaNovaProvider } from './providers/sambanova';\nimport { GeminiProvider } from './providers/gemini';\n\nexport * from './core/types';\nexport { validateChatRequest } from './core/validation';\nexport { ProviderRegistry } from './core/registry';\nexport { OpenAIProvider } from './providers/openai';\nexport { AnthropicProvider } from './providers/anthropic';\nexport { GroqProvider } from './providers/groq';\nexport { OpenRouterProvider } from './providers/openrouter';\nexport { SambaNovaProvider } from './providers/sambanova';\nexport { GeminiProvider } from './providers/gemini';\n\nfunction env(name: string): string | undefined {\n  try {\n    // Bun/node\n    // eslint-disable-next-line no-undef\n    return (typeof process !== 'undefined' && process?.env?.[name]) || undefined;\n  } catch {\n    return undefined;\n  }\n}\n\nfunction keyFromEnv(provider: ProviderId): string | undefined {\n  const map: Record<ProviderId, string> = {\n    openai: 'OPENAI_API_KEY',\n    anthropic: 'ANTHROPIC_API_KEY',\n    groq: 'GROQ_API_KEY',\n    gemini: 'GEMINI_API_KEY',\n    openrouter: 'OPENROUTER_API_KEY',\n    sambanova: 'SAMBANOVA_API_KEY',\n  };\n  return env(map[provider]);\n}\n\nfunction defaultBase(provider: ProviderId): string | undefined {\n  switch (provider) {\n    case 'openai':\n      return 'https://api.openai.com/v1';\n    case 'anthropic':\n      return 'https://api.anthropic.com';\n    default:\n      return undefined;\n  }\n}\n\nexport class HRI {\n  readonly registry: ProviderRegistry;\n  private config: ClientConfig;\n\n  constructor(config: ClientConfig = {}, registry?: ProviderRegistry) {\n    this.config = config;\n    this.registry = registry ?? new ProviderRegistry();\n  }\n\n  static createDefault(config: ClientConfig = {}): HRI {\n    const hri = new HRI(config);\n    hri.use(new OpenAIProvider());\n    hri.use(new AnthropicProvider());\n    hri.use(new GroqProvider());\n    hri.use(new OpenRouterProvider());\n    hri.use(new SambaNovaProvider());\n    hri.use(new GeminiProvider());\n    return hri;\n  }\n\n  use(provider: Provider) {\n    this.registry.register(provider);\n    return this;\n  }\n\n  private apiKeyFor(provider: ProviderId): string | undefined {\n    return this.config.apiKeys?.[provider] ?? keyFromEnv(provider);\n  }\n\n  private baseUrlFor(provider: ProviderId): string | undefined {\n    if (this.config.baseUrls?.[provider]) return this.config.baseUrls[provider];\n    if (this.config.proxy) {\n      // Opinionated proxy mapping paths; user can override via baseUrls\n      switch (provider) {\n        case 'openai':\n          return `${this.config.proxy.replace(/\\/$/, '')}/openai/v1`;\n        case 'anthropic':\n          return `${this.config.proxy.replace(/\\/$/, '')}/anthropic`;\n        default:\n          return this.config.proxy;\n      }\n    }\n    return defaultBase(provider);\n  }\n\n  async chat(req: ChatRequest): Promise<ChatResponse> {\n    const v = validateChatRequest(req);\n    const provider = this.registry.get(v.provider as ProviderId);\n    if (!provider) throw new Error(`Provider not registered: ${v.provider}`);\n    const key = this.apiKeyFor(provider.id);\n    const base = this.baseUrlFor(provider.id);\n    return provider.chat({ ...v, stream: false }, key, base);\n  }\n\n  streamChat(req: ChatRequest): AsyncIterable<ChatStreamChunk> {\n    const v = validateChatRequest({ ...req, stream: true });\n    const provider = this.registry.get(v.provider as ProviderId);\n    if (!provider || !provider.streamChat) {\n      throw new Error(`Provider does not support streaming: ${v.provider}`);\n    }\n    const key = this.apiKeyFor(provider.id);\n    const base = this.baseUrlFor(provider.id);\n    return provider.streamChat(v, key, base);\n  }\n\n  // Helper: aggregate streamed content to a single string\n  async streamToText(req: ChatRequest): Promise<string> {\n    let text = '';\n    for await (const c of this.streamChat({ ...req, stream: true })) {\n      const delta = c.delta?.content;\n      if (typeof delta === 'string') text += delta;\n    }\n    return text;\n  }\n\n  // Automatic Function Calling (OpenAI-compatible)\n  // Executes tool calls returned by the model until completion or maxCalls reached.\n  async chatWithTools(\n    req: ChatRequest & { tools?: ToolDef[]; tool_choice?: ChatRequest['tool_choice'] },\n    handlers: Record<string, (args: any) => any | Promise<any>>,\n    opts: { maxCalls?: number } = {}\n  ): Promise<ChatResponse> {\n    const maxCalls = opts.maxCalls ?? 10;\n    const messages: ChatMessage[] = [...req.messages];\n    let calls = 0;\n\n    // Allow forcing a first tool via tool_choice, but automatically switch to 'auto' after first round\n    let toolChoice = req.tool_choice;\n    while (calls <= maxCalls) {\n      const res = await this.chat({ ...req, messages, stream: false, tool_choice: toolChoice });\n      const choice = res.choices?.[0];\n      const msg = choice?.message as ChatMessage | undefined;\n      const toolCalls = (msg?.tool_calls as ToolCall[] | undefined) || [];\n\n      if (!toolCalls.length) {\n        return res;\n      }\n\n      // Append the assistant message containing the tool_calls\n      messages.push({ role: 'assistant', content: msg?.content || '', tool_calls: toolCalls });\n\n      // Execute tools and push tool results as messages\n      for (const tc of toolCalls) {\n        if (tc.type !== 'function') continue;\n        const name = tc.function?.name;\n        const handler = handlers[name];\n        let args: any = {};\n        try {\n          args = tc.function?.arguments ? JSON.parse(tc.function.arguments) : {};\n        } catch {\n          args = {};\n        }\n        let out: any;\n        try {\n          if (!handler) throw new Error(`No handler for tool: ${name}`);\n          out = await handler(args);\n        } catch (e: any) {\n          out = { error: String(e?.message || e) };\n        }\n        const content = typeof out === 'string' ? out : JSON.stringify(out);\n        messages.push({ role: 'tool', content, tool_call_id: tc.id });\n      }\n\n      calls += 1;\n      if (toolChoice === 'required' || (toolChoice && typeof toolChoice === 'object')) {\n        toolChoice = 'none';\n      } else {\n        toolChoice = 'auto';\n      }\n      // Next loop will send updated messages; keep tools in request and continue.\n      // Optionally, user may set tool_choice:'none' in req to force a final answer.\n    }\n\n    throw new Error(`Exceeded max tool calls (${maxCalls}) during chatWithTools()`);\n  }\n\n  // Streaming AFC (OpenAI-compatible)\n  // Yields chunks as they arrive; when a tool_calls finish is reached, executes tools and continues streaming.\n  async *streamWithTools(\n    req: ChatRequest & { tools?: ToolDef[]; tool_choice?: ChatRequest['tool_choice'] },\n    handlers: Record<string, (args: any) => any | Promise<any>>,\n    opts: { maxCalls?: number } = {}\n  ): AsyncIterable<ChatStreamChunk> {\n    const maxCalls = opts.maxCalls ?? 10;\n    const baseReq = { ...req, stream: true } as ChatRequest;\n    const messages: ChatMessage[] = [...req.messages];\n    let calls = 0;\n\n    // Allow a first forced tool_choice, then revert to 'auto'\n    let toolChoice = req.tool_choice;\n    while (calls <= maxCalls) {\n      const stream = this.streamChat({ ...baseReq, messages, tool_choice: toolChoice });\n      // Accumulate tool_calls deltas by id\n      const toolAccum = new Map<string, { name: string | undefined; args: string }>();\n      for await (const chunk of stream) {\n        // Aggregate tool call delta if present\n        const deltas = chunk.delta?.tool_calls || [];\n        for (const t of deltas) {\n          if (!t) continue;\n          const id = t.id || '0';\n          const acc = toolAccum.get(id) ?? { name: t.function?.name, args: '' };\n          if (t.function?.name) acc.name = t.function.name;\n          if (t.function?.arguments) acc.args += t.function.arguments;\n          toolAccum.set(id, acc);\n        }\n        yield chunk;\n      }\n\n      // If no tool calls were emitted during this streamed turn, end streaming\n      if (toolAccum.size === 0) return;\n\n      // Append assistant message with tool_calls (filter invalid entries without a function name)\n      const toolCalls = Array.from(toolAccum.entries())\n        .filter(([, v]) => v.name && v.name.length > 0)\n        .map(([id, v]) => ({\n          id,\n          type: 'function' as const,\n          function: { name: v.name as string, arguments: v.args || '{}' },\n        }));\n\n      // If nothing valid accumulated, end the stream gracefully\n      if (toolCalls.length === 0) return;\n      messages.push({ role: 'assistant', content: '', tool_calls: toolCalls });\n\n      // Execute and append tool results\n      for (const tc of toolCalls) {\n        const handler = handlers[tc.function.name];\n        let args: any = {};\n        try {\n          args = tc.function.arguments ? JSON.parse(tc.function.arguments) : {};\n        } catch {\n          args = {};\n        }\n        let out: any;\n        try {\n          if (!handler) throw new Error(`No handler for tool: ${tc.function.name}`);\n          out = await handler(args);\n        } catch (e: any) {\n          out = { error: String(e?.message || e) };\n        }\n        const content = typeof out === 'string' ? out : JSON.stringify(out);\n        messages.push({ role: 'tool', content, tool_call_id: tc.id });\n      }\n\n      calls += 1;\n      // After a tool round: if the initial choice was 'required' or a specific function,\n      // force a final answer to avoid infinite tool loops; otherwise fall back to 'auto'.\n      if (toolChoice === 'required' || (toolChoice && typeof toolChoice === 'object')) {\n        toolChoice = 'none';\n      } else {\n        toolChoice = 'auto';\n      }\n      // Loop to continue streaming the follow-up model response\n    }\n\n    throw new Error(`Exceeded max tool calls (${maxCalls}) during streamWithTools()`);\n  }\n}\n"
  ],
  "mappings": "gmBAEO,MAAM,CAAiB,CACpB,UAAY,IAAI,IAExB,QAAQ,CAAC,EAAoB,CAC3B,KAAK,UAAU,IAAI,EAAS,GAAI,CAAQ,EAG1C,GAAG,CAAC,EAAsC,CACxC,OAAO,KAAK,UAAU,IAAI,CAAE,EAG9B,GAAG,CAAC,EAAyB,CAC3B,OAAO,KAAK,UAAU,IAAI,CAAE,EAEhC,CChBA,iBAAS,YAAQ,YAAQ,aAAQ,WAAS,cAAO,YAAU,aAG3D,IAAM,GAAiB,EAAO,CAC5B,GAAI,EAAO,EACX,KAAM,EAAO,EACb,SAAU,EAAO,CACf,KAAM,EAAO,EACb,UAAW,EAAO,CACpB,CAAC,CACH,CAAC,EAEK,GAAoB,EAAO,CAC/B,KAAM,EAAO,EACb,QAAS,EAAO,EAChB,KAAM,EAAS,EAAO,CAAC,EACvB,aAAc,EAAS,EAAO,CAAC,EAC/B,WAAY,EAAS,EAAM,EAAc,CAAC,CAC5C,CAAC,EAEY,GAAoB,EAAO,CACtC,SAAU,EAAO,EACjB,MAAO,EAAO,EACd,SAAU,EAAM,EAAiB,EACjC,YAAa,EAAS,EAAO,CAAC,EAC9B,WAAY,EAAS,EAAO,CAAC,EAC7B,MAAO,EAAS,EAAO,CAAC,EACxB,OAAQ,EAAS,EAAQ,CAAC,EAC1B,KAAM,EAAS,EAAQ,CAAC,EACxB,aAAc,EAAS,GAAO,EAAO,CAAC,CAAC,CACzC,CAAC,EAEM,SAAS,EAAmB,CAAC,EAAsC,CAExE,IAD4B,CAAC,SAAU,YAAa,OAAQ,SAAU,aAAc,WAAW,EACpF,SAAS,CAAgB,EAClC,MAAM,IAAI,MAAM,qBAAqB,GAAI,EAItC,SAAS,CAAmB,CAAC,EAA2B,CAC7D,IAAM,EAAS,GAAkB,UAAU,CAAU,EACrD,IAAK,EAAO,QAAS,CACnB,IAAM,EAAM,EAAO,OAAO,WAAW,GAAK,kBAC1C,MAAM,IAAI,MAAM,CAAG,EAErB,GAAoB,EAAO,KAAK,QAAQ,EACxC,IAAM,EAAU,GAAa,QAErB,QAAO,eAAiB,GAAe,CAAC,EAChD,MAAO,IAAM,EAAO,KAAc,QAAO,cAAa,QAAO,EC9C/D,IAAI,EAEJ,SAAS,EAAM,EAAY,CACzB,GAAI,CAEF,OAAO,OAAO,UAAY,eAAkB,QAAgB,UAAU,KACtE,KAAM,CACN,MAAO,IAIX,SAAS,EAAU,CAAC,EAAiC,CACnD,GAAI,CACF,IAAM,EAAI,IAAI,IAAI,CAAG,EACrB,MAAO,GAAG,EAAE,aAAa,EAAE,OAC3B,KAAM,CACN,QAIJ,eAAsB,CAAmB,CAAC,EAAuC,CAC/E,IAAK,GAAO,EAAG,OAEf,GAAI,CAGF,IADa,OAAO,UAAY,aAAgB,QAAgB,KAAK,kBAAoB,IAC/E,OACV,KAAM,CACN,OAGF,IAAM,EAAS,GAAW,CAAG,EAC7B,IAAK,EAAQ,OACb,GAAI,CACF,IAAM,EAAS,KAAa,mBACpB,QAAS,EACjB,IAAK,EAAO,EAAQ,IAAI,IACxB,IAAI,EAAO,EAAM,IAAI,CAAM,EAC3B,IAAK,EACH,EAAO,IAAI,EAAK,EAAQ,CACtB,YAAa,EACb,WAAY,EACZ,iBAAkB,IAClB,oBAAqB,KACvB,CAAC,EACD,EAAM,IAAI,EAAQ,CAAI,EAExB,OAAO,EACP,KAAM,CAEN,QC5CG,SAAS,CAAO,CAAC,EAAc,EAAsB,CAC1D,GAAI,EAAK,WAAW,MAAM,EAAG,OAAO,EACpC,MAAO,GAAG,EAAK,QAAQ,MAAO,EAAE,KAAK,EAAK,QAAQ,MAAO,EAAE,IAK7D,eAAsB,CAAI,CAAC,EAAa,EAAuB,CAAC,EAAsB,CACpF,IAAQ,SAAS,OAAQ,UAAU,CAAC,EAAG,OAAM,UAAW,EAClD,EAAoB,CACxB,SACA,UACA,KAAM,OAAO,IAAS,UAAY,aAAgB,WAAa,EAAO,EAAO,KAAK,UAAU,CAAI,EAAI,OACpG,SAGA,UAAW,EACb,EAGM,EAAa,MAAM,EAAoB,CAAG,EAChD,GAAI,EACD,EAAa,WAAa,EAG7B,OAAO,MAAM,EAAK,CAAI,EAGxB,eAAuB,EAAS,CAAC,EAA4D,CAC3F,IAAM,EAAS,EAAO,UAAU,EAC1B,EAAU,IAAI,YAChB,EAAS,GACb,GAAI,CACF,MAAO,GAAM,CACX,IAAQ,OAAM,SAAU,MAAM,EAAO,KAAK,EAC1C,GAAI,EAAM,MACV,GAAU,EAAQ,OAAO,EAAO,CAAE,OAAQ,EAAK,CAAC,EAChD,IAAI,EACJ,OAAQ,EAAM,EAAO,QAAQ;AAAA,CAAI,KAAO,GAAI,CAC1C,IAAM,EAAO,EAAO,MAAM,EAAG,CAAG,EAChC,EAAS,EAAO,MAAM,EAAM,CAAC,EAC7B,MAAM,EAAK,QAAQ,MAAO,EAAE,GAGhC,GAAI,EAAO,OAAS,EAClB,MAAM,SAER,CACA,EAAO,YAAY,GAIvB,eAAuB,CAAQ,CAAC,EAA8F,CAC5H,IAAI,EAAsB,CAAC,EACvB,EACJ,cAAiB,KAAQ,GAAU,CAAM,EAAG,CAC1C,GAAI,IAAS,GAAI,CACf,IAAM,EAAO,EAAU,OAAS,EAAU,KAAK;AAAA,CAAI,EAAI,OACvD,MAAM,GAAQ,EAAQ,CAAE,QAAO,MAAK,EAAI,KACxC,EAAY,CAAC,EACb,EAAQ,OACR,SAEF,GAAI,EAAK,WAAW,GAAG,EACrB,SAEF,IAAM,EAAM,EAAK,QAAQ,GAAG,EACtB,EAAQ,IAAQ,GAAK,EAAO,EAAK,MAAM,EAAG,CAAG,EAC7C,EAAQ,IAAQ,GAAK,GAAK,EAAK,MAAM,EAAM,CAAC,EAAE,QAAQ,OAAQ,EAAE,EACtE,GAAI,IAAU,QAAS,EAAQ,EAC1B,QAAI,IAAU,OAAQ,EAAU,KAAK,CAAK,GC5EnD,IAAM,EAAe,4BAErB,SAAS,EAAc,CAAC,EAAW,EAAoC,CACrE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAmC,CAC9C,GAAK,SACL,KAAO,SACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KACN,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE/C,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,gBAAgB,EAAI,WAAW,GAAM,EAEvD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KACN,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAG/C,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,uBAAuB,EAAI,WAAW,GAAM,EAG9D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SACf,OAEF,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,MAAO,EAAG,IAKlB,CCtIA,IAAM,EAAe,4BACf,EAAc,aAEpB,SAAS,CAAmB,CAAC,EAAoG,CAC/H,IAAM,EAAwB,CAAC,EACzB,EAA8D,CAAC,EACrE,QAAW,KAAK,EAAI,SAClB,GAAI,EAAE,OAAS,SACb,EAAY,KAAK,EAAE,OAAO,EACrB,QAAI,EAAE,OAAS,QAAU,EAAE,OAAS,YACzC,EAAS,KAAK,CAAE,KAAM,EAAE,KAAM,QAAS,EAAE,OAAQ,CAAC,EAKtD,MAAO,CAAE,OADM,EAAY,OAAS,EAAY,KAAK;AAAA,CAAI,EAAI,OAC5C,UAAS,EAG5B,SAAS,EAAc,CAAC,EAAW,EAAyB,EAA6B,CAEvF,IAAM,EAAmB,CAAE,KAAM,YAAa,QADjC,MAAM,QAAQ,EAAK,OAAO,EAAI,EAAK,QAAQ,IAAI,CAAC,IAAW,EAAE,MAAQ,EAAE,EAAE,KAAK,EAAE,EAAI,EAAK,UAAU,IAAI,MAAQ,EAChE,EAC5D,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrC,MAAO,EACP,QAAS,CAAC,CAAE,MAAO,EAAG,QAAS,EAAK,cAAe,EAAK,aAAe,IAAK,CAAC,EAC7E,SAAU,EACV,IAAK,CACP,EAGK,MAAM,CAAsC,CACjD,GAAK,YACL,KAAO,iBAED,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CAErF,IAAM,EAAM,EAAQ,GAAW,EADlB,cACoC,GACzC,SAAQ,YAAa,EAAoB,CAAG,EAC9C,EAAU,CACd,YAAa,GAAU,GACvB,eAAgB,mBAChB,oBAAqB,KACjB,EAAI,cAAgB,CAAC,CAC3B,EACM,EAAY,CAChB,MAAO,EAAI,MACX,WAAY,EAAI,YAAc,KAC9B,YAAa,EAAI,YACjB,SACA,UACF,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAE1D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,GAAI,EAAI,KAAK,QAGzC,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CAErE,IAAM,EAAM,EAAQ,GAAW,EADlB,cACoC,GACzC,SAAQ,YAAa,EAAoB,CAAG,EAC9C,EAAU,CACd,YAAa,GAAU,GACvB,eAAgB,mBAChB,OAAU,oBACV,oBAAqB,KACjB,EAAI,cAAgB,CAAC,CAC3B,EACM,EAAY,CAChB,MAAO,EAAI,MACX,WAAY,EAAI,YAAc,KAC9B,YAAa,EAAI,YACjB,SACA,WACA,OAAQ,EACV,EACM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,0BAA0B,EAAI,WAAW,GAAM,EAEjE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAO,EAAK,KAClB,GAAI,IAAS,uBAAyB,EAAK,OAAO,OAAS,aAKzD,KAJ+B,CAC7B,MAAO,CAAE,KAAM,YAAa,QAAS,EAAK,MAAM,MAAQ,EAAG,EAC3D,IAAK,CACP,EAEK,QAAI,IAAS,eAClB,OAEF,KAAM,IAKd,CCxGA,IAAM,EAAe,iCAErB,SAAS,EAAc,CAAC,EAAW,EAAkC,CACnE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAiC,CAC5C,GAAK,OACL,KAAO,2BACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,cAAc,EAAI,WAAW,GAAM,EAErD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,qBAAqB,EAAI,WAAW,GAAM,EAG5D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CChIA,IAAM,EAAe,+BAErB,SAAS,EAAc,CAAC,EAAW,EAAwC,CACzE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAuC,CAClD,GAAK,aACL,KAAO,iCACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,oBAAoB,EAAI,WAAW,GAAM,EAE3D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,2BAA2B,EAAI,WAAW,GAAM,EAGlE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CChIA,IAAM,EAAe,8BAErB,SAAS,EAAc,CAAC,EAAW,EAAuC,CACxE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAsC,CACjD,GAAK,YACL,KAAO,gCACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,mBAAmB,EAAI,WAAW,GAAM,EAE1D,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,0BAA0B,EAAI,WAAW,GAAM,EAGjE,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CC/HA,IAAM,EAAe,0DAErB,SAAS,EAAc,CAAC,EAAW,EAAoC,CACrE,IAAM,GAAW,EAAK,SAAW,CAAC,GAAG,IAAI,CAAC,EAAQ,KAAe,CAC/D,MAAO,EAAE,OAAS,EAClB,QAAU,EAAE,SAAW,CAAE,KAAM,YAAa,QAAS,EAAG,EACxD,cAAe,EAAE,eAAiB,IACpC,EAAE,EACF,MAAO,CACL,GAAI,EAAK,IAAM,UACf,QAAS,EAAK,SAAW,KAAK,MAAM,KAAK,IAAI,EAAI,IAAI,EACrD,MAAO,EAAK,OAAS,UACrB,UACA,MAAO,EAAK,MACZ,SAAU,EACV,IAAK,CACP,EAGF,SAAS,CAAY,CAAC,EAA4B,EAAoD,CACpG,MAAO,IAAM,GAAK,CAAC,KAAQ,GAAK,CAAC,CAAG,EAG/B,MAAM,CAAmC,CAC9C,GAAK,SACL,KAAO,6BACC,MAAM,CAAC,EAAwB,CACrC,GAAI,CAAE,MAAO,eAAe,KAAK,CAAK,EAAK,KAAM,CAAE,MAAO,SAGtD,KAAI,CAAC,EAAkB,EAAiB,EAAyC,CACrF,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,kBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAC3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,GAAI,CACX,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,gBAAgB,EAAI,WAAW,GAAM,EAEvD,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,OAAO,GAAe,EAAM,KAAK,EAAE,QAG9B,UAAU,CAAC,EAAkB,EAAiB,EAAkB,CACrE,IAAM,EAAM,EAAQ,GAAW,EAAc,mBAAmB,EAC1D,EAAU,EACd,CACE,cAAiB,UAAU,GAAU,KACrC,eAAgB,mBAChB,OAAU,mBACZ,EACA,EAAI,YACN,EACM,EAAY,CAChB,MAAO,EAAI,MACX,SAAU,EAAI,SACd,YAAa,EAAI,YACjB,MAAO,EAAI,MACX,OAAQ,EACV,EACA,GAAI,EAAI,YAAc,KACpB,GAAI,KAAK,OAAO,EAAI,KAAK,EAAI,EAAa,sBAAwB,EAAI,WACjE,KAAC,EAAa,WAAa,EAAI,WAEtC,GAAI,EAAI,MAAO,EAAK,MAAQ,EAAI,MAChC,GAAI,EAAI,YAAa,EAAK,YAAc,EAAI,YAC5C,GAAI,EAAI,KAAM,EAAK,gBAAkB,CAAE,KAAM,aAAc,EAE3D,IAAM,EAAM,MAAM,EAAK,EAAK,CAAE,OAAQ,OAAQ,UAAS,OAAM,OAAQ,EAAI,MAAO,CAAC,EACjF,IAAK,EAAI,KAAO,EAAI,KAAM,CACxB,IAAM,EAAO,MAAM,EAAI,KAAK,EAC5B,MAAM,IAAI,MAAM,uBAAuB,EAAI,WAAW,GAAM,EAG9D,cAAiB,KAAO,EAAS,EAAI,IAAI,EAAG,CAC1C,IAAK,IAAQ,EAAI,KAAM,SACvB,GAAI,EAAI,OAAS,SAAU,OAC3B,GAAI,CACF,IAAM,EAAO,KAAK,MAAM,EAAI,IAAI,EAC1B,EAAS,EAAK,UAAU,GACxB,EAAQ,GAAQ,OAAS,CAAC,EAsBhC,KArB+B,CAC7B,GAAI,EAAK,GACT,QAAS,EAAK,QACd,MAAO,EAAK,MACZ,MAAO,CACL,KAAM,EAAM,KACZ,QAAS,EAAM,QACf,WAAY,MAAM,QAAQ,EAAM,UAAU,EACtC,EAAM,WAAW,IAAI,CAAC,KAAY,CAChC,GAAI,EAAE,IAAM,OAAO,EAAE,OAAS,CAAC,EAC/B,KAAM,WACN,SAAU,CACR,KAAM,EAAE,UAAU,KAClB,UAAW,EAAE,UAAU,WAAa,EACtC,CACF,EAAE,EACF,MACN,EACA,cAAe,GAAQ,eAAiB,KACxC,IAAK,CACP,EAEA,KAAM,IAKd,CCtGA,SAAS,EAAG,CAAC,EAAkC,CAC7C,GAAI,CAGF,OAAQ,OAAO,UAAY,aAAe,SAAS,MAAM,IAAU,OACnE,KAAM,CACN,QAIJ,SAAS,EAAU,CAAC,EAA0C,CAS5D,OAAO,GARiC,CACtC,OAAQ,iBACR,UAAW,oBACX,KAAM,eACN,OAAQ,iBACR,WAAY,qBACZ,UAAW,mBACb,EACe,EAAS,EAG1B,SAAS,EAAW,CAAC,EAA0C,CAC7D,OAAQ,OACD,SACH,MAAO,gCACJ,YACH,MAAO,oCAEP,QAIC,MAAM,CAAI,CACN,SACD,OAER,WAAW,CAAC,EAAuB,CAAC,EAAG,EAA6B,CAClE,KAAK,OAAS,EACd,KAAK,SAAW,GAAY,IAAI,QAG3B,cAAa,CAAC,EAAuB,CAAC,EAAQ,CACnD,IAAM,EAAM,IAAI,EAAI,CAAM,EAO1B,OANA,EAAI,IAAI,IAAI,CAAgB,EAC5B,EAAI,IAAI,IAAI,CAAmB,EAC/B,EAAI,IAAI,IAAI,CAAc,EAC1B,EAAI,IAAI,IAAI,CAAoB,EAChC,EAAI,IAAI,IAAI,CAAmB,EAC/B,EAAI,IAAI,IAAI,CAAgB,EACrB,EAGT,GAAG,CAAC,EAAoB,CAEtB,OADA,KAAK,SAAS,SAAS,CAAQ,EACxB,KAGD,SAAS,CAAC,EAA0C,CAC1D,OAAO,KAAK,OAAO,UAAU,IAAa,GAAW,CAAQ,EAGvD,UAAU,CAAC,EAA0C,CAC3D,GAAI,KAAK,OAAO,WAAW,GAAW,OAAO,KAAK,OAAO,SAAS,GAClE,GAAI,KAAK,OAAO,MAEd,OAAQ,OACD,SACH,MAAO,GAAG,KAAK,OAAO,MAAM,QAAQ,MAAO,EAAE,kBAC1C,YACH,MAAO,GAAG,KAAK,OAAO,MAAM,QAAQ,MAAO,EAAE,sBAE7C,OAAO,KAAK,OAAO,MAGzB,OAAO,GAAY,CAAQ,OAGvB,KAAI,CAAC,EAAyC,CAClD,IAAM,EAAI,EAAoB,CAAG,EAC3B,EAAW,KAAK,SAAS,IAAI,EAAE,QAAsB,EAC3D,IAAK,EAAU,MAAM,IAAI,MAAM,4BAA4B,EAAE,UAAU,EACvE,IAAM,EAAM,KAAK,UAAU,EAAS,EAAE,EAChC,EAAO,KAAK,WAAW,EAAS,EAAE,EACxC,OAAO,EAAS,KAAK,IAAK,EAAG,OAAQ,EAAM,EAAG,EAAK,CAAI,EAGzD,UAAU,CAAC,EAAkD,CAC3D,IAAM,EAAI,EAAoB,IAAK,EAAK,OAAQ,EAAK,CAAC,EAChD,EAAW,KAAK,SAAS,IAAI,EAAE,QAAsB,EAC3D,IAAK,IAAa,EAAS,WACzB,MAAM,IAAI,MAAM,wCAAwC,EAAE,UAAU,EAEtE,IAAM,EAAM,KAAK,UAAU,EAAS,EAAE,EAChC,EAAO,KAAK,WAAW,EAAS,EAAE,EACxC,OAAO,EAAS,WAAW,EAAG,EAAK,CAAI,OAInC,aAAY,CAAC,EAAmC,CACpD,IAAI,EAAO,GACX,cAAiB,KAAK,KAAK,WAAW,IAAK,EAAK,OAAQ,EAAK,CAAC,EAAG,CAC/D,IAAM,EAAQ,EAAE,OAAO,QACvB,GAAI,OAAO,IAAU,SAAU,GAAQ,EAEzC,OAAO,OAKH,cAAa,CACjB,EACA,EACA,EAA8B,CAAC,EACR,CACvB,IAAM,EAAW,EAAK,UAAY,GAC5B,EAA0B,CAAC,GAAG,EAAI,QAAQ,EAC5C,EAAQ,EAGR,EAAa,EAAI,YACrB,MAAO,GAAS,EAAU,CACxB,IAAM,EAAM,MAAM,KAAK,KAAK,IAAK,EAAK,WAAU,OAAQ,GAAO,YAAa,CAAW,CAAC,EAElF,EADS,EAAI,UAAU,IACT,QACd,EAAa,GAAK,YAAyC,CAAC,EAElE,IAAK,EAAU,OACb,OAAO,EAIT,EAAS,KAAK,CAAE,KAAM,YAAa,QAAS,GAAK,SAAW,GAAI,WAAY,CAAU,CAAC,EAGvF,QAAW,KAAM,EAAW,CAC1B,GAAI,EAAG,OAAS,WAAY,SAC5B,IAAM,EAAO,EAAG,UAAU,KACpB,EAAU,EAAS,GACrB,EAAY,CAAC,EACjB,GAAI,CACF,EAAO,EAAG,UAAU,UAAY,KAAK,MAAM,EAAG,SAAS,SAAS,EAAI,CAAC,EACrE,KAAM,CACN,EAAO,CAAC,EAEV,IAAI,EACJ,GAAI,CACF,IAAK,EAAS,MAAM,IAAI,MAAM,wBAAwB,GAAM,EAC5D,EAAM,MAAM,EAAQ,CAAI,EACxB,MAAO,EAAQ,CACf,EAAM,CAAE,MAAO,OAAO,GAAG,SAAW,CAAC,CAAE,EAEzC,IAAM,EAAU,OAAO,IAAQ,SAAW,EAAM,KAAK,UAAU,CAAG,EAClE,EAAS,KAAK,CAAE,KAAM,OAAQ,UAAS,aAAc,EAAG,EAAG,CAAC,EAI9D,GADA,GAAS,EACL,IAAe,YAAe,GAAc,OAAO,IAAe,SACpE,EAAa,OAEb,OAAa,OAMjB,MAAM,IAAI,MAAM,4BAA4B,2BAAkC,QAKzE,eAAe,CACpB,EACA,EACA,EAA8B,CAAC,EACC,CAChC,IAAM,EAAW,EAAK,UAAY,GAC5B,EAAU,IAAK,EAAK,OAAQ,EAAK,EACjC,EAA0B,CAAC,GAAG,EAAI,QAAQ,EAC5C,EAAQ,EAGR,EAAa,EAAI,YACrB,MAAO,GAAS,EAAU,CACxB,IAAM,EAAS,KAAK,WAAW,IAAK,EAAS,WAAU,YAAa,CAAW,CAAC,EAE1E,EAAY,IAAI,IACtB,cAAiB,KAAS,EAAQ,CAEhC,IAAM,EAAS,EAAM,OAAO,YAAc,CAAC,EAC3C,QAAW,KAAK,EAAQ,CACtB,IAAK,EAAG,SACR,IAAM,EAAK,EAAE,IAAM,IACb,EAAM,EAAU,IAAI,CAAE,GAAK,CAAE,KAAM,EAAE,UAAU,KAAM,KAAM,EAAG,EACpE,GAAI,EAAE,UAAU,KAAM,EAAI,KAAO,EAAE,SAAS,KAC5C,GAAI,EAAE,UAAU,UAAW,EAAI,MAAQ,EAAE,SAAS,UAClD,EAAU,IAAI,EAAI,CAAG,EAEvB,MAAM,EAIR,GAAI,EAAU,OAAS,EAAG,OAG1B,IAAM,EAAY,MAAM,KAAK,EAAU,QAAQ,CAAC,EAC7C,OAAO,GAAI,KAAO,EAAE,MAAQ,EAAE,KAAK,OAAS,CAAC,EAC7C,IAAI,EAAE,EAAI,MAAQ,CACjB,KACA,KAAM,WACN,SAAU,CAAE,KAAM,EAAE,KAAgB,UAAW,EAAE,MAAQ,IAAK,CAChE,EAAE,EAGJ,GAAI,EAAU,SAAW,EAAG,OAC5B,EAAS,KAAK,CAAE,KAAM,YAAa,QAAS,GAAI,WAAY,CAAU,CAAC,EAGvE,QAAW,KAAM,EAAW,CAC1B,IAAM,EAAU,EAAS,EAAG,SAAS,MACjC,EAAY,CAAC,EACjB,GAAI,CACF,EAAO,EAAG,SAAS,UAAY,KAAK,MAAM,EAAG,SAAS,SAAS,EAAI,CAAC,EACpE,KAAM,CACN,EAAO,CAAC,EAEV,IAAI,EACJ,GAAI,CACF,IAAK,EAAS,MAAM,IAAI,MAAM,wBAAwB,EAAG,SAAS,MAAM,EACxE,EAAM,MAAM,EAAQ,CAAI,EACxB,MAAO,EAAQ,CACf,EAAM,CAAE,MAAO,OAAO,GAAG,SAAW,CAAC,CAAE,EAEzC,IAAM,EAAU,OAAO,IAAQ,SAAW,EAAM,KAAK,UAAU,CAAG,EAClE,EAAS,KAAK,CAAE,KAAM,OAAQ,UAAS,aAAc,EAAG,EAAG,CAAC,EAM9D,GAHA,GAAS,EAGL,IAAe,YAAe,GAAc,OAAO,IAAe,SACpE,EAAa,OAEb,OAAa,OAKjB,MAAM,IAAI,MAAM,4BAA4B,6BAAoC,EAEpF",
  "debugId": "7C32D889D9CE69EB64756E2164756E21",
  "names": []
}